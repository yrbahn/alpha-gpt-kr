#!/usr/bin/env python3
"""
ìž¬ë¬´ì œí‘œ ê¸°ë°˜ ì•ŒíŒŒ (Fundamental Alpha)
ë§¤ì¶œ, ì˜ì—…ì´ìµ, EPS, ROE ë“± íŽ€ë”ë©˜í„¸ ì§€í‘œ í™œìš©
"""

import sys
import os
from pathlib import Path
from datetime import date
import pandas as pd
import numpy as np
from dotenv import load_dotenv
import psycopg2
import openai
import random
from multiprocessing import Pool, cpu_count

project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from alpha_gpt_kr.mining.operators import AlphaOperators

load_dotenv()

def get_db_connection():
    return psycopg2.connect(
        host=os.getenv('DB_HOST', '192.168.0.248'),
        port=int(os.getenv('DB_PORT', 5432)),
        database=os.getenv('DB_NAME', 'marketsense'),
        user=os.getenv('DB_USER', 'yrbahn'),
        password=os.getenv('DB_PASSWORD', '1234')
    )

def load_fundamental_data():
    """ìž¬ë¬´ì œí‘œ + ê°€ê²© ë°ì´í„° í†µí•©"""
    print("ðŸ“Š ìž¬ë¬´ì œí‘œ ë°ì´í„° ë¡œë“œ ì¤‘...")
    print("   - ì†ìµê³„ì‚°ì„œ (ë§¤ì¶œ, ì˜ì—…ì´ìµ, ìˆœì´ìµ)")
    print("   - ìž¬ë¬´ìƒíƒœí‘œ (ìžì‚°, ë¶€ì±„, ìžë³¸)")
    print("   - í˜„ê¸ˆíë¦„í‘œ")
    print("   - ì£¼ê°€ ë°ì´í„°")
    
    conn = get_db_connection()
    
    # ìž¬ë¬´ ë°ì´í„° ìžˆëŠ” ì¢…ëª© ì¤‘ ì‹œì´ ìƒìœ„ 100
    query_stocks = """
        SELECT DISTINCT ON (s.ticker)
            s.id, s.ticker, s.name
        FROM stocks s
        JOIN price_data p ON s.id = p.stock_id
        JOIN financial_statements f ON s.id = f.stock_id
        WHERE s.is_active = true
        AND p.date = (SELECT MAX(date) FROM price_data)
        AND f.revenue IS NOT NULL
        AND f.period_end >= CURRENT_DATE - INTERVAL '365 days'
        ORDER BY s.ticker, (p.close * p.volume) DESC
        LIMIT 100
    """
    stocks_df = pd.read_sql(query_stocks, conn)
    stock_ids = stocks_df['id'].tolist()
    stock_id_list = ', '.join(map(str, stock_ids))
    
    # 1. ê°€ê²© ë°ì´í„° (2ë…„)
    query_price = f"""
        SELECT s.ticker, p.date, p.close, p.volume
        FROM price_data p
        JOIN stocks s ON p.stock_id = s.id
        WHERE p.stock_id IN ({stock_id_list})
        AND p.date >= CURRENT_DATE - INTERVAL '730 days'
        ORDER BY s.ticker, p.date
    """
    price_df = pd.read_sql(query_price, conn)
    close = price_df.pivot(index='date', columns='ticker', values='close')
    volume = price_df.pivot(index='date', columns='ticker', values='volume')
    
    # 2. ìž¬ë¬´ì œí‘œ (ë¶„ê¸°ë³„, EPS ì œì™¸)
    query_financial = f"""
        SELECT 
            s.ticker,
            f.period_end as date,
            f.revenue,
            f.operating_income,
            f.net_income,
            f.total_assets,
            f.total_equity,
            f.total_liabilities,
            f.operating_cash_flow,
            f.free_cash_flow
        FROM financial_statements f
        JOIN stocks s ON f.stock_id = s.id
        WHERE f.stock_id IN ({stock_id_list})
        AND f.period_end >= CURRENT_DATE - INTERVAL '730 days'
        AND f.revenue IS NOT NULL
        ORDER BY s.ticker, f.period_end
    """
    
    fin_df = pd.read_sql(query_financial, conn)
    conn.close()
    
    # ìž¬ë¬´ ë°ì´í„°ë¥¼ ì¼ë³„ ë°ì´í„°ë¡œ ë³€í™˜ (forward fill)
    revenue = fin_df.pivot(index='date', columns='ticker', values='revenue')
    operating_income = fin_df.pivot(index='date', columns='ticker', values='operating_income')
    net_income = fin_df.pivot(index='date', columns='ticker', values='net_income')
    total_assets = fin_df.pivot(index='date', columns='ticker', values='total_assets')
    total_equity = fin_df.pivot(index='date', columns='ticker', values='total_equity')
    total_liabilities = fin_df.pivot(index='date', columns='ticker', values='total_liabilities')
    operating_cf = fin_df.pivot(index='date', columns='ticker', values='operating_cash_flow')
    free_cf = fin_df.pivot(index='date', columns='ticker', values='free_cash_flow')
    
    # ì¼ë³„ ê°€ê²© ì¸ë±ìŠ¤ì— ë§žì¶° ìž¬ë¬´ ë°ì´í„° forward fill
    all_dates = close.index
    revenue = revenue.reindex(all_dates).fillna(method='ffill')
    operating_income = operating_income.reindex(all_dates).fillna(method='ffill')
    net_income = net_income.reindex(all_dates).fillna(method='ffill')
    total_assets = total_assets.reindex(all_dates).fillna(method='ffill')
    total_equity = total_equity.reindex(all_dates).fillna(method='ffill')
    total_liabilities = total_liabilities.reindex(all_dates).fillna(method='ffill')
    operating_cf = operating_cf.reindex(all_dates).fillna(method='ffill')
    free_cf = free_cf.reindex(all_dates).fillna(method='ffill')
    
    print(f"âœ… {len(close.columns)}ê°œ ì¢…ëª©, {len(close)}ì¼ ë°ì´í„°")
    print(f"   ìž¬ë¬´ì œí‘œ: {len(fin_df)}ê°œ ë¶„ê¸° ë°ì´í„°")
    
    return {
        # ê°€ê²©
        'close': close,
        'volume': volume,
        'returns': close.pct_change(),
        # ìž¬ë¬´ì œí‘œ (EPS ì œì™¸)
        'revenue': revenue,
        'operating_income': operating_income,
        'net_income': net_income,
        'total_assets': total_assets,
        'total_equity': total_equity,
        'total_liabilities': total_liabilities,
        'operating_cf': operating_cf,
        'free_cf': free_cf
    }

def generate_fundamental_alphas():
    """ìž¬ë¬´ì œí‘œ ê¸°ë°˜ ì•ŒíŒŒ ìƒì„±"""
    
    print("\nðŸ¤– ìž¬ë¬´ì œí‘œ ê¸°ë°˜ ì•ŒíŒŒ ìƒì„± ì¤‘...")
    
    client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
    
    prompt = """ë‹¹ì‹ ì€ Value íˆ¬ìž ì „ë¬¸ í€€íŠ¸ìž…ë‹ˆë‹¤.
ìž¬ë¬´ì œí‘œë¥¼ í™œìš©í•œ 10ì¼ ë³´ìœ  ì•ŒíŒŒë¥¼ ìƒì„±í•˜ì„¸ìš”.

## ðŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ ìž¬ë¬´ ë°ì´í„°

### ì†ìµê³„ì‚°ì„œ
- revenue: ë§¤ì¶œ
- operating_income: ì˜ì—…ì´ìµ
- net_income: ìˆœì´ìµ

### ìž¬ë¬´ìƒíƒœí‘œ
- total_assets: ì´ìžì‚°
- total_equity: ìžë³¸ (ìˆœìžì‚°)
- total_liabilities: ë¶€ì±„

### í˜„ê¸ˆíë¦„í‘œ
- operating_cf: ì˜ì—…í™œë™í˜„ê¸ˆíë¦„
- free_cf: ìž‰ì—¬í˜„ê¸ˆíë¦„ (FCF)

âš ï¸ EPS ë°ì´í„° ì—†ìŒ - ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”

### ê°€ê²© ë°ì´í„°
- close: ì£¼ê°€
- volume: ê±°ëž˜ëŸ‰
- returns: ìˆ˜ìµë¥ 

## ðŸ”§ ì—°ì‚°ìž
- ts_delta(x, period): Nì¼ ì „ ëŒ€ë¹„ ë³€í™”
- ts_mean(x, window): ì´ë™í‰ê· 
- ts_rank(x, window): ìˆœìœ„ 0~1
- normed_rank(x): íš¡ë‹¨ë©´ ìˆœìœ„

## ðŸ’¡ Value & Quality ì „ëžµ

### 1. Profitability (ìˆ˜ìµì„±)
- **ROE**: net_income / total_equity (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
- **ì˜ì—…ì´ìµë¥ **: operating_income / revenue
- **ìˆœì´ìµë¥ **: net_income / revenue
- **ROA**: net_income / total_assets

### 2. Growth (ì„±ìž¥ì„±)
- **ë§¤ì¶œ ì„±ìž¥**: ts_delta(revenue, 365) / revenue
- **ìˆœì´ìµ ì„±ìž¥**: ts_delta(net_income, 365) / net_income
- **ì˜ì—…ì´ìµ ì„±ìž¥**: ts_delta(operating_income, 365) / operating_income
- **ìžë³¸ ì„±ìž¥**: ts_delta(total_equity, 365) / total_equity

### 3. Quality (ìž¬ë¬´ ê±´ì „ì„±)
- **ë¶€ì±„ë¹„ìœ¨**: total_liabilities / total_equity (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
- **ìžê¸°ìžë³¸ë¹„ìœ¨**: total_equity / total_assets (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
- **FCF ë§ˆì§„**: free_cf / revenue
- **ì´ìµì˜ ì§ˆ**: operating_cf / net_income (1 ì´ìƒ ì¢‹ìŒ)

### 4. ë³µí•© ì „ëžµ
- **ê³ ROE + ì €ë¶€ì±„**: net_income/total_equity * (-total_liabilities/total_equity)
- **ì„±ìž¥ + ìˆ˜ìµì„±**: ts_delta(revenue, 365)/revenue * operating_income/revenue
- **í˜„ê¸ˆíë¦„ ìš°ìˆ˜**: free_cf/revenue * operating_cf/net_income

## ðŸ“ ì•ŒíŒŒ 50ê°œ ìƒì„±

ë§¤ìš° ë‹¤ì–‘í•œ ì ‘ê·¼ìœ¼ë¡œ 50ê°œë¥¼ ìž‘ì„±í•˜ì„¸ìš”. ë‹¨ìˆœí•œ ê²ƒë¶€í„° ë³µìž¡í•œ ì¡°í•©ê¹Œì§€:

ALPHA_1: AlphaOperators.normed_rank(net_income / total_equity)
ALPHA_2: AlphaOperators.normed_rank(operating_income / revenue)
ALPHA_3: AlphaOperators.ts_rank(AlphaOperators.ts_delta(revenue, 365) / revenue, 60)
ALPHA_4: AlphaOperators.normed_rank(-total_liabilities / total_equity)
ALPHA_5: AlphaOperators.normed_rank(free_cf / revenue)
ALPHA_6: AlphaOperators.normed_rank(operating_cf / net_income)
ALPHA_7: AlphaOperators.ts_rank(AlphaOperators.ts_delta(net_income, 365) / net_income, 60)
ALPHA_8: AlphaOperators.normed_rank(total_equity / total_assets)
ALPHA_9: AlphaOperators.normed_rank(net_income / total_assets)
ALPHA_10: AlphaOperators.normed_rank(net_income / revenue)
ALPHA_11: AlphaOperators.ts_rank(AlphaOperators.ts_delta(operating_income, 365) / operating_income, 60)
ALPHA_12: AlphaOperators.normed_rank(operating_income / total_assets)
ALPHA_13: AlphaOperators.normed_rank(revenue / total_assets)
ALPHA_14: AlphaOperators.ts_rank(AlphaOperators.ts_delta(total_equity, 365) / total_equity, 60)
ALPHA_15: AlphaOperators.normed_rank(free_cf / net_income)
ALPHA_16: AlphaOperators.normed_rank((net_income / total_equity) * (-total_liabilities / total_equity))
ALPHA_17: AlphaOperators.normed_rank((operating_income / revenue) * (total_equity / total_assets))
ALPHA_18: AlphaOperators.ts_rank(AlphaOperators.ts_delta(revenue, 365) / revenue, 60) * AlphaOperators.normed_rank(operating_income / revenue)
ALPHA_19: AlphaOperators.normed_rank((free_cf / revenue) * (operating_cf / net_income))
ALPHA_20: AlphaOperators.normed_rank(net_income / total_equity) + AlphaOperators.normed_rank(-total_liabilities / total_equity)
...
ALPHA_50: [ë” ë³µìž¡í•œ ì¡°í•©, 4-5ê°œ ì§€í‘œ ê²°í•©]

ë§¤ìš° ì°½ì˜ì ì¸ ì¡°í•©ì„ ë§Œë“œì„¸ìš”! ë‹¨ìˆœí•œ ê²ƒë¶€í„° ë§¤ìš° ë³µìž¡í•œ ê²ƒê¹Œì§€ ê³¨ê³ ë£¨!
"""

    response = client.chat.completions.create(
        model="gpt-4-turbo-preview",
        messages=[
            {"role": "system", "content": "You are a fundamental analysis expert."},
            {"role": "user", "content": prompt}
        ],
        temperature=1.0,  # ë†’ì€ ë‹¤ì–‘ì„±
        max_tokens=4000  # 50ê°œ ì•ŒíŒŒ ìƒì„±
    )
    
    content = response.choices[0].message.content
    
    alphas = []
    for line in content.split('\n'):
        line = line.strip()
        if 'AlphaOperators' in line:
            if ':' in line:
                line = line.split(':', 1)[1].strip()
            if '#' in line:
                line = line.split('#')[0].strip()
            if line:
                alphas.append(line)
    
    print(f"âœ… {len(alphas)}ê°œ ìž¬ë¬´ ì•ŒíŒŒ ìƒì„±")
    return alphas

_global_data = None

def set_global_data(data):
    global _global_data
    _global_data = data

def evaluate_alpha_ic_worker(alpha_expr):
    """10ì¼ í›„ ìˆ˜ìµë¥  ì˜ˆì¸¡"""
    global _global_data
    data = _global_data
    
    try:
        # ë³€ìˆ˜ ë°”ì¸ë”© (EPS ì œì™¸)
        close = data['close']
        volume = data['volume']
        returns = data['returns']
        revenue = data['revenue']
        operating_income = data['operating_income']
        net_income = data['net_income']
        total_assets = data['total_assets']
        total_equity = data['total_equity']
        total_liabilities = data['total_liabilities']
        operating_cf = data['operating_cf']
        free_cf = data['free_cf']
        
        # 10ì¼ í›„ ìˆ˜ìµë¥ 
        returns_forward_10 = close.pct_change(10).shift(-10)
        
        alpha_values = eval(alpha_expr)
        
        ic_list = []
        for date in alpha_values.index[:-10]:
            alpha_cs = alpha_values.loc[date]
            returns_cs = returns_forward_10.loc[date]
            valid = alpha_cs.notna() & returns_cs.notna() & (alpha_cs != np.inf) & (alpha_cs != -np.inf)
            
            if valid.sum() > 10:
                ic = alpha_cs[valid].corr(returns_cs[valid])
                if not np.isnan(ic):
                    ic_list.append(ic)
        
        if len(ic_list) < 10:
            return (alpha_expr, -999.0)
        
        return (alpha_expr, np.mean(ic_list))
        
    except Exception as e:
        return (alpha_expr, -999.0)

def genetic_programming_parallel(seed_alphas, data, generations=15, population_size=200):
    """ë³‘ë ¬ GP"""
    num_workers = min(cpu_count(), 8)
    
    print(f"\nðŸ§¬ ë³‘ë ¬ GP ì§„í™” (ìž¬ë¬´ ì•ŒíŒŒ)")
    print(f"   ì„¸ëŒ€: {generations}, ê°œì²´ìˆ˜: {population_size}")
    
    population = seed_alphas[:population_size]
    while len(population) < population_size:
        population.append(random.choice(seed_alphas))
    
    set_global_data(data)
    
    for gen in range(generations):
        print(f"\n  ì„¸ëŒ€ {gen+1}/{generations}")
        
        with Pool(num_workers, initializer=set_global_data, initargs=(data,)) as pool:
            results = pool.map(evaluate_alpha_ic_worker, population)
        
        fitness_scores = sorted(results, key=lambda x: x[1], reverse=True)
        
        best_ic = fitness_scores[0][1]
        print(f"    ìµœê³  IC: {best_ic:.4f}")
        
        next_population = []
        
        elite_count = population_size // 5
        for alpha, _ in fitness_scores[:elite_count]:
            next_population.append(alpha)
        
        while len(next_population) < population_size:
            parent = random.choice([a for a, _ in fitness_scores[:population_size//2]])
            next_population.append(parent)
        
        population = next_population
    
    with Pool(num_workers, initializer=set_global_data, initargs=(data,)) as pool:
        final_results = pool.map(evaluate_alpha_ic_worker, population)
    
    final_fitness = sorted(final_results, key=lambda x: x[1], reverse=True)
    
    print(f"\nâœ… GP ì™„ë£Œ! ìµœê³  IC: {final_fitness[0][1]:.4f}")
    
    return final_fitness

def main():
    print("=" * 70)
    print("ìž¬ë¬´ì œí‘œ ê¸°ë°˜ ì•ŒíŒŒ (Fundamental Alpha)")
    print("=" * 70)
    print()
    
    # ë°ì´í„° ë¡œë“œ
    data = load_fundamental_data()
    
    # LLM ì•ŒíŒŒ ìƒì„±
    seed_alphas = generate_fundamental_alphas()
    
    print("\nðŸ“Š ìƒì„±ëœ ìž¬ë¬´ ì•ŒíŒŒ:")
    for i, alpha in enumerate(seed_alphas, 1):
        print(f"   {i}. {alpha[:80]}...")
    
    # GP ì§„í™” (Large-scale: 50 seeds â†’ 200 population)
    evolved_alphas = genetic_programming_parallel(
        seed_alphas=seed_alphas,
        data=data,
        generations=15,  # ë” ë§Žì€ ì„¸ëŒ€
        population_size=200  # ëŒ€ê·œëª¨ íƒìƒ‰
    )
    
    # ê²°ê³¼
    print("\n" + "=" * 70)
    print("ðŸ† ì§„í™”ëœ ìƒìœ„ 5ê°œ ìž¬ë¬´ ì•ŒíŒŒ")
    print("=" * 70)
    
    for i, (alpha, ic) in enumerate(evolved_alphas[:5], 1):
        print(f"\n{i}. IC: {ic:.4f}")
        print(f"   {alpha}")
    
    # DB ì €ìž¥
    best_alpha, best_ic = evolved_alphas[0]
    
    conn = get_db_connection()
    cur = conn.cursor()
    
    try:
        cur.execute("""
            INSERT INTO alpha_performance
            (alpha_formula, start_date, is_active, sharpe_ratio, notes)
            VALUES (%s, %s, %s, %s, %s)
            ON CONFLICT (alpha_formula, start_date) DO UPDATE
            SET sharpe_ratio = EXCLUDED.sharpe_ratio, notes = EXCLUDED.notes
        """, (
            best_alpha,
            date.today(),
            True,
            float(best_ic * 10),
            f"IC: {best_ic:.4f}, Fundamental (Value+Quality+Growth), 10-day forward"
        ))
        conn.commit()
        print("\nâœ… DB ì €ìž¥ ì™„ë£Œ")
    finally:
        cur.close()
        conn.close()
    
    print("\nðŸŽ‰ ìž¬ë¬´ ì•ŒíŒŒ ìƒì„± ì™„ë£Œ!")

if __name__ == "__main__":
    main()
