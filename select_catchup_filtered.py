#!/usr/bin/env python3
"""
Catch-up ì¢…ëª© ì„ ì • (ì´ë¯¸ ë§ì´ ì˜¤ë¥¸ ì¢…ëª© ì œì™¸)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ë¬¸ì œ: ê¸°ì¡´ ì•ŒíŒŒëŠ” ëª¨ë©˜í…€ ë¹„ì¤‘ì´ ë†’ì•„ "ì´ë¯¸ í¬ê²Œ ì˜¤ë¥¸" ì¢…ëª©ì„ ê³„ì† ë½‘ìŒ
í•´ê²°:
  1) ì¥ê¸° ìˆ˜ìµë¥ (60d, 90d)ë¡œ "ì´ë¯¸ ë§ì´ ì˜¤ë¥¸" ì¢…ëª© ì œì™¸
  2) ëª¨ë©˜í…€ ê°€ì†(ìµœê·¼ 10d vs ì´ì „ 10d) + ì‹¤ì  ê°œì„  ì•ŒíŒŒ ì‚¬ìš©
  3) v6 ì¬ë¬´ì¶”ì„¸ ë¹„ì¤‘ í™•ëŒ€

ì „ëµ: "3ê°œì›”ê°„ ìƒëŒ€ì ìœ¼ë¡œ ëœ ì˜¬ëì§€ë§Œ, ìµœê·¼ ê°€ì† + ì‹¤ì  ê°œì„ " ì¢…ëª©
"""

import sys
import os
import json as _json
from pathlib import Path
import pandas as pd
import numpy as np
from dotenv import load_dotenv
import psycopg2

project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from alpha_gpt_kr.mining.operators import AlphaOperators as ops

load_dotenv()


def get_db_connection():
    return psycopg2.connect(
        host=os.getenv('DB_HOST', '192.168.0.248'),
        port=int(os.getenv('DB_PORT', 5432)),
        database=os.getenv('DB_NAME', 'marketsense'),
        user=os.getenv('DB_USER', 'yrbahn'),
        password=os.getenv('DB_PASSWORD', '1234')
    )


# â”€â”€ ë°ì´í„° ë¡œë“œ â”€â”€
print("ğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
conn = get_db_connection()

stocks_df = pd.read_sql("""
    SELECT s.id, s.ticker, s.name, s.market_cap
    FROM stocks s
    WHERE s.is_active = true
    AND s.market_cap IS NOT NULL
    AND EXISTS (
        SELECT 1 FROM price_data p
        WHERE p.stock_id = s.id
        AND p.date >= CURRENT_DATE - INTERVAL '730 days'
        LIMIT 1
    )
    ORDER BY s.market_cap DESC
    LIMIT 2000
""", conn)

stock_ids = stocks_df['id'].tolist()
stock_id_list = ', '.join(map(str, stock_ids))

ticker_name = dict(zip(stocks_df['ticker'], stocks_df['name']))
ticker_mcap = dict(zip(stocks_df['ticker'], stocks_df['market_cap']))
id_ticker = dict(zip(stocks_df['id'], stocks_df['ticker']))

price_df = pd.read_sql(f"""
    SELECT s.ticker, p.date, p.close, p.volume
    FROM price_data p
    JOIN stocks s ON p.stock_id = s.id
    WHERE p.stock_id IN ({stock_id_list})
    AND p.date >= CURRENT_DATE - INTERVAL '730 days'
    ORDER BY s.ticker, p.date
""", conn)

close = price_df.pivot(index='date', columns='ticker', values='close')
volume = price_df.pivot(index='date', columns='ticker', values='volume')
returns = close.pct_change()

# ì¬ë¬´ ì¶”ì„¸ ë°ì´í„°
print("   ì¬ë¬´ ì¶”ì„¸ ë°ì´í„° ë¡œë“œ ì¤‘...")
fin_df = pd.read_sql(f"""
    SELECT stock_id, period_end, revenue, operating_income, net_income, raw_data
    FROM financial_statements
    WHERE stock_id IN ({stock_id_list})
    ORDER BY stock_id, period_end
""", conn)
conn.close()

def _parse_raw(row):
    rd = row.get('raw_data')
    if rd is None:
        return {'quarter_type': None}
    if isinstance(rd, str):
        rd = _json.loads(rd)
    return {'quarter_type': rd.get('quarter', '')}

raw_parsed = fin_df.apply(_parse_raw, axis=1, result_type='expand')
fin_df = pd.concat([fin_df, raw_parsed], axis=1)
fin_df['ticker'] = fin_df['stock_id'].map(id_ticker)
fin_df = fin_df.dropna(subset=['ticker'])
fin_df = fin_df[fin_df['quarter_type'] != 'ì—°ê°„'].copy()
fin_df = fin_df.sort_values(['ticker', 'period_end'])

# ë°¸ë¥˜ì—ì´ì…˜ í•„í„°
print("   ë°¸ë¥˜ì—ì´ì…˜ í•„í„° ê³„ì‚° ì¤‘...")
valuation = {}
for ticker, grp in fin_df.groupby('ticker'):
    grp = grp.sort_values('period_end')
    recent = grp.tail(4)
    if len(recent) < 2:
        continue
    trailing_oi = recent['operating_income'].sum()
    trailing_ni = recent['net_income'].sum()
    mcap = ticker_mcap.get(ticker, 0)
    per = mcap / trailing_ni if mcap and mcap > 0 and trailing_ni and trailing_ni > 0 else np.nan
    valuation[ticker] = {
        'trailing_oi': trailing_oi,
        'trailing_ni': trailing_ni,
        'per': per,
    }

FILTER_PER_MAX = 50
filtered_out = set()
for ticker, v in valuation.items():
    reasons = []
    if v['trailing_ni'] is None or v['trailing_ni'] <= 0:
        reasons.append("ìˆœì´ìµ ì ì")
    elif v['per'] is not None and v['per'] > FILTER_PER_MAX:
        reasons.append(f"PER {v['per']:.1f}x")
    if v['trailing_oi'] is not None and v['trailing_oi'] <= 0:
        reasons.append("ì˜ì—…ì ì")
    if reasons:
        filtered_out.add(ticker)
no_data_tickers = set(close.columns) - set(valuation.keys())
exclude_tickers = filtered_out | no_data_tickers

# ì¶”ì„¸ ë³€ìˆ˜
trend_records = []
for ticker, grp in fin_df.groupby('ticker'):
    grp = grp.sort_values('period_end').reset_index(drop=True)
    for i in range(len(grp)):
        row = grp.iloc[i]
        rec = {'ticker': ticker, 'period_end': row['period_end']}
        if i >= 1:
            prev = grp.iloc[i - 1]
            if prev['operating_income'] and prev['operating_income'] != 0:
                rec['oi_qoq'] = (row['operating_income'] - prev['operating_income']) / abs(prev['operating_income'])
        if i >= 3:
            yoy_prev = grp.iloc[i - 3]
            if row['period_end'].month == yoy_prev['period_end'].month:
                if yoy_prev['operating_income'] and yoy_prev['operating_income'] != 0:
                    rec['oi_yoy'] = (row['operating_income'] - yoy_prev['operating_income']) / abs(yoy_prev['operating_income'])
        if i >= 2:
            oi_vals = [grp.iloc[j]['operating_income'] for j in range(i - 2, i + 1)
                       if grp.iloc[j]['operating_income'] is not None and not np.isnan(grp.iloc[j]['operating_income'])]
            if len(oi_vals) == 3:
                rec['oi_trend'] = (oi_vals[2] - oi_vals[0]) / (abs(oi_vals[0]) + 1e-10)
        trend_records.append(rec)

trend_df = pd.DataFrame(trend_records)
_empty = pd.DataFrame(np.nan, index=close.index, columns=close.columns)
trend_vars = {}
for field in ['oi_qoq', 'oi_yoy', 'oi_trend']:
    if field not in trend_df.columns:
        continue
    pivot = trend_df.pivot_table(index='period_end', columns='ticker', values=field, aggfunc='last')
    if pivot.empty or pivot.notna().sum().sum() < 50:
        continue
    daily = pivot.reindex(close.index).ffill().reindex(columns=close.columns)
    trend_vars[f'{field}_rank'] = daily.rank(axis=1, pct=True)

oi_trend_rank = trend_vars.get('oi_trend_rank', _empty)
oi_yoy_rank = trend_vars.get('oi_yoy_rank', _empty)
oi_qoq_rank = trend_vars.get('oi_qoq_rank', _empty)

print(f"âœ… {len(close.columns)}ê°œ ì¢…ëª©, {len(close)}ì¼ ë°ì´í„°")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì¥ê¸° ìˆ˜ìµë¥  ê³„ì‚°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
latest_date = close.index[-1]

# ê° ê¸°ê°„ë³„ ìˆ˜ìµë¥ 
periods = {
    '20d': 20,
    '40d': 40,
    '60d': 60,
    '90d': 90,
    '120d': 120,
}
ret_by_period = {}
for label, days in periods.items():
    if len(close) > days:
        ret_by_period[label] = (close.iloc[-1] / close.iloc[-days] - 1) * 100
    else:
        ret_by_period[label] = pd.Series(0, index=close.columns)

# ëª¨ë©˜í…€ ê°€ì†ë„: ìµœê·¼ 10ì¼ ìˆ˜ìµë¥  - ì´ì „ 10ì¼ ìˆ˜ìµë¥ 
mom_recent_10d = (close.iloc[-1] / close.iloc[-10] - 1) * 100
mom_prev_10d = (close.iloc[-10] / close.iloc[-20] - 1) * 100
mom_accel = mom_recent_10d - mom_prev_10d

# 52ì£¼(250ì¼) ìµœê³ ê°€ ëŒ€ë¹„ í˜„ì¬ ìœ„ì¹˜
if len(close) > 250:
    high_250d = close.iloc[-250:].max()
    low_250d = close.iloc[-250:].min()
    position_52w = (close.iloc[-1] - low_250d) / (high_250d - low_250d + 1e-10) * 100
else:
    position_52w = pd.Series(50, index=close.columns)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë¨¼ì € ê¸°ì¡´ ìƒìœ„ ì¢…ëª©ë“¤ì˜ ì¥ê¸° ìˆ˜ìµë¥  í™•ì¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print(f"\n{'='*110}")
print(f"ğŸ“Š ê¸°ì¡´ ìƒìœ„ ì¢…ëª©ë“¤ì˜ ì¥ê¸° ìˆ˜ìµë¥  ì ê²€ (ê¸°ì¤€ì¼: {latest_date})")
print(f"{'='*110}")

# ê¸°ì¡´ ì•™ìƒë¸” (select_top5.pyì™€ ë™ì¼)
v3_alpha = ops.normed_rank(
    ops.cwise_mul(
        ops.cwise_mul(
            ops.ts_delta_ratio(close, 25),
            ops.div(ops.ts_median(volume, 10), ops.ts_std(volume, 15))
        ),
        ops.ts_maxmin_scale(close, 28)
    )
)
v6_alpha = ops.normed_rank(
    ops.add(ops.add(oi_trend_rank, oi_yoy_rank), oi_qoq_rank)
)
v6_filled = v6_alpha.fillna(0.5)
old_ensemble = ops.normed_rank(v3_alpha * 0.5 + v6_filled * 0.5)
old_scores = old_ensemble.loc[latest_date].dropna().sort_values(ascending=False)
old_filtered = old_scores[~old_scores.index.isin(exclude_tickers)]

print(f"\n{'ìˆœìœ„':>4} {'ì¢…ëª©ì½”ë“œ':<10} {'ì¢…ëª©ëª…':<14} {'í˜„ì¬ê°€':>10} {'20d':>8} {'60d':>8} {'90d':>8} {'120d':>8} {'52Wìœ„ì¹˜':>8} {'íŒì •':<8}")
print(f"{'-'*100}")

for i, (ticker, score) in enumerate(old_filtered.head(10).items(), 1):
    name = ticker_name.get(ticker, '?')
    price = close.loc[latest_date, ticker]
    r20 = ret_by_period['20d'].get(ticker, 0)
    r60 = ret_by_period['60d'].get(ticker, 0)
    r90 = ret_by_period['90d'].get(ticker, 0)
    r120 = ret_by_period['120d'].get(ticker, 0)
    pos = position_52w.get(ticker, 50)

    # íŒì •: 60ì¼ ìˆ˜ìµë¥  > 30% ë˜ëŠ” 52ì£¼ ìœ„ì¹˜ > 80%ë©´ "ê³¼ì—´"
    if r60 > 30 or pos > 80:
        verdict = "âš ï¸ ê³¼ì—´"
    elif r60 > 15:
        verdict = "ğŸ”¶ ìƒìŠ¹ì¤‘"
    else:
        verdict = "âœ… ì´ˆê¸°"

    print(f"  {i:>2}. {ticker:<10} {name:<14} {price:>10,.0f}ì› {r20:>+6.1f}% {r60:>+6.1f}% {r90:>+6.1f}% {r120:>+6.1f}% {pos:>6.0f}%  {verdict}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ìƒˆ ì „ëµ: ê°€ì†Ã—ì‹¤ì  ì•ŒíŒŒ + "ê³¼ì—´ ì¢…ëª© ì œì™¸" í•„í„°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ê³¼ì—´ í•„í„°: 60ì¼ ìˆ˜ìµë¥  30% ì´ìƒ ë˜ëŠ” 52ì£¼ ê³ ì  80% ì´ìƒ ì œì™¸
OVERHEAT_60D_MAX = 30  # 60ì¼ ìˆ˜ìµë¥  ìƒí•œ
OVERHEAT_52W_MAX = 80  # 52ì£¼ ìœ„ì¹˜ ìƒí•œ

overheated = set()
for ticker in close.columns:
    r60 = ret_by_period['60d'].get(ticker, 0)
    pos = position_52w.get(ticker, 50)
    if r60 > OVERHEAT_60D_MAX or pos > OVERHEAT_52W_MAX:
        overheated.add(ticker)

all_exclude = exclude_tickers | overheated

print(f"\n{'='*110}")
print(f"ğŸ”¥ ê³¼ì—´ í•„í„° ì ìš©")
print(f"   60ì¼ ìˆ˜ìµë¥  > {OVERHEAT_60D_MAX}% ë˜ëŠ” 52ì£¼ ìœ„ì¹˜ > {OVERHEAT_52W_MAX}% â†’ ì œì™¸")
print(f"   ê³¼ì—´ ì¢…ëª©: {len(overheated)}ê°œ ì œì™¸")
print(f"   PER+í‘ì í•„í„°: {len(exclude_tickers)}ê°œ ì œì™¸")
print(f"   ìµœì¢… ìœ ë‹ˆë²„ìŠ¤: {len(close.columns) - len(all_exclude)}ì¢…ëª©")
print(f"{'='*110}")


# â”€â”€ ì•ŒíŒŒ 1: ëª¨ë©˜í…€ ê°€ì† Ã— ì‹¤ì  ê°œì„  (5c) â”€â”€
# ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ Test IC +0.0280
accel_alpha = ops.normed_rank(
    ops.cwise_mul(
        ops.cwise_mul(
            ops.minus(ops.ts_delta_ratio(close, 10), ops.ts_delta_ratio(close.shift(10), 10)),
            ops.div(ops.ts_mean(volume, 5), ops.ts_mean(volume, 20))
        ),
        oi_yoy_rank
    )
)

# â”€â”€ ì•ŒíŒŒ 2: v6 ì¬ë¬´ì¶”ì„¸ (ê°€ì¥ ê°•ë ¥í•œ ë‹¨ì¼ ì•ŒíŒŒ) â”€â”€
# ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ Test IC +0.0592 (20d fwd)
# ì´ë¯¸ ê³„ì‚°ë¨: v6_alpha

# â”€â”€ ì•ŒíŒŒ 3: v3 ê°€ê²© ëª¨ë©˜í…€ (ê°€ì†ê³¼ êµ¬ë¶„) â”€â”€
# ì´ë¯¸ ê³„ì‚°ë¨: v3_alpha

# â”€â”€ Catch-up ì•™ìƒë¸”: ê°€ì† 30% + v6 50% + v3 20% â”€â”€
# ê°€ì† ë¹„ì¤‘ì„ ë†’ì´ê³  ìˆœìˆ˜ ëª¨ë©˜í…€(v3) ë¹„ì¤‘ ì¶•ì†Œ
accel_filled = accel_alpha.fillna(0.5)
catchup_ensemble = ops.normed_rank(
    accel_filled * 0.30 + v6_filled * 0.50 + v3_alpha * 0.20
)

catchup_scores = catchup_ensemble.loc[latest_date].dropna().sort_values(ascending=False)
catchup_filtered = catchup_scores[~catchup_scores.index.isin(all_exclude)]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ê²°ê³¼ ì¶œë ¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print(f"\n{'='*120}")
print(f"ğŸ¯ Catch-up ì¢…ëª© ì„ ì •: 'ì•„ì§ ëœ ì˜¬ëì§€ë§Œ ê³§ ì˜¤ë¥¼' ì¢…ëª©")
print(f"   ì•ŒíŒŒ: ëª¨ë©˜í…€ê°€ì† 30% + ì¬ë¬´ì¶”ì„¸ 50% + ê°€ê²©ëª¨ë©˜í…€ 20%")
print(f"   í•„í„°: PER â‰¤ {FILTER_PER_MAX}x + í‘ì + 60dìˆ˜ìµë¥  â‰¤ {OVERHEAT_60D_MAX}% + 52Wìœ„ì¹˜ â‰¤ {OVERHEAT_52W_MAX}%")
print(f"   ìœ ë‹ˆë²„ìŠ¤: {len(catchup_scores)}ì¢…ëª© â†’ {len(catchup_filtered)}ì¢…ëª© í†µê³¼")
print(f"{'='*120}")
print(f"{'ìˆœìœ„':>4} {'ì¢…ëª©ì½”ë“œ':<10} {'ì¢…ëª©ëª…':<14} {'ì ìˆ˜':>7} {'ê°€ì†':>6} {'v6':>6} {'v3':>6} {'í˜„ì¬ê°€':>10} {'20d':>7} {'60d':>7} {'90d':>7} {'52W':>6} {'PER':>6} {'NI(ì–µ)':>8}")
print(f"{'-'*120}")

for i, (ticker, score) in enumerate(catchup_filtered.head(15).items(), 1):
    name = ticker_name.get(ticker, '?')
    acc_s = accel_alpha.loc[latest_date, ticker] if ticker in accel_alpha.columns else np.nan
    v6_s = v6_alpha.loc[latest_date, ticker] if ticker in v6_alpha.columns else np.nan
    v3_s = v3_alpha.loc[latest_date, ticker] if ticker in v3_alpha.columns else np.nan
    price = close.loc[latest_date, ticker]
    r20 = ret_by_period['20d'].get(ticker, 0)
    r60 = ret_by_period['60d'].get(ticker, 0)
    r90 = ret_by_period['90d'].get(ticker, 0)
    pos = position_52w.get(ticker, 50)
    v = valuation.get(ticker, {})
    per = v.get('per', np.nan)
    ni = v.get('trailing_ni', 0)
    ni_ì–µ = ni / 1e8 if ni else 0
    per_s = f"{per:.1f}x" if per and not np.isnan(per) else "  -"
    acc_str = f"{acc_s:.3f}" if not np.isnan(acc_s) else "  -  "
    v6_str = f"{v6_s:.3f}" if not np.isnan(v6_s) else "  -  "

    print(f"  {i:>2}. {ticker:<10} {name:<14} {score:.4f} {acc_str} {v6_str} {v3_s:.3f} {price:>10,.0f}ì› {r20:>+5.1f}% {r60:>+5.1f}% {r90:>+5.1f}% {pos:>4.0f}% {per_s:>6} {ni_ì–µ:>7,.0f}ì–µ")


# â”€â”€ ê³¼ì—´ í•„í„°ë¡œ ì œì™¸ëœ ìƒìœ„ ì¢…ëª© (ì°¸ê³ ìš©) â”€â”€
overheated_top = catchup_scores[catchup_scores.index.isin(overheated) & ~catchup_scores.index.isin(exclude_tickers)].head(5)
if not overheated_top.empty:
    print(f"\nğŸ”¥ ê³¼ì—´ í•„í„°ë¡œ ì œì™¸ëœ ê³ ì ìˆ˜ ì¢…ëª©:")
    for ticker, score in overheated_top.items():
        name = ticker_name.get(ticker, '?')
        r60 = ret_by_period['60d'].get(ticker, 0)
        r90 = ret_by_period['90d'].get(ticker, 0)
        pos = position_52w.get(ticker, 50)
        print(f"     {ticker:<10} {name:<14} ì ìˆ˜ {score:.4f}  60d: {r60:+.1f}%  90d: {r90:+.1f}%  52W: {pos:.0f}%")


# â”€â”€ í•˜ìœ„ ì¢…ëª© â”€â”€
print(f"\n{'='*120}")
print(f"ğŸ“‰ í•˜ìœ„ 5ì¢…ëª© (ìˆ í›„ë³´)")
print(f"{'='*120}")
for i, (ticker, score) in enumerate(catchup_filtered.tail(5).items(), 1):
    name = ticker_name.get(ticker, '?')
    price = close.loc[latest_date, ticker]
    r60 = ret_by_period['60d'].get(ticker, 0)
    r90 = ret_by_period['90d'].get(ticker, 0)
    pos = position_52w.get(ticker, 50)
    v = valuation.get(ticker, {})
    per = v.get('per', np.nan)
    per_s = f"{per:.1f}x" if per and not np.isnan(per) else "  -"
    print(f"  {i:>2}. {ticker:<10} {name:<14} ì ìˆ˜ {score:.4f} {price:>10,.0f}ì› 60d:{r60:>+5.1f}% 90d:{r90:>+5.1f}% 52W:{pos:>4.0f}% {per_s}")


print(f"\n{'='*120}")
print(f"ğŸ’¡ í•´ì„")
print(f"{'='*120}")
print(f"   âœ… ì„ ì • ê¸°ì¤€:")
print(f"      1) PER â‰¤ {FILTER_PER_MAX}x + ì˜ì—…Â·ìˆœì´ìµ í‘ì (ë°¸ë¥˜ í•„í„°)")
print(f"      2) 60ì¼ ìˆ˜ìµë¥  â‰¤ {OVERHEAT_60D_MAX}% (ì´ë¯¸ ë§ì´ ì˜¤ë¥¸ ì¢…ëª© ì œì™¸)")
print(f"      3) 52ì£¼ ê³ ì  ëŒ€ë¹„ {OVERHEAT_52W_MAX}% ì´í•˜ ìœ„ì¹˜ (ê³ ì  ê·¼ì²˜ ì œì™¸)")
print(f"      4) ëª¨ë©˜í…€ 'ê°€ì†' ì‹ í˜¸ (ìµœê·¼ 10ì¼ vs ì´ì „ 10ì¼ ìˆ˜ìµë¥  ì°¨ì´)")
print(f"      5) ì˜ì—…ì´ìµ ì¶”ì„¸ ê°œì„  (YoY + QoQ + 3Q ì¶”ì„¸)")
print(f"   â†’ '60ì¼ê°„ 30% ë¯¸ë§Œ ìƒìŠ¹ + ì‹¤ì  ê°œì„  + ìµœê·¼ ê°€ì†' ì¢…ëª©")
print(f"   â†’ í•œë‹¬(20ì˜ì—…ì¼) ë³´ìœ  ì „ëµ")
