#!/usr/bin/env python3
"""
Catch-up Alpha v2: "ê³§ ì˜¤ë¥¼ ì¢…ëª©" ì¬ì„¤ê³„
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

v1 êµí›ˆ: ìˆœìˆ˜ ì—­ëª¨ë©˜í…€(ëœ ì˜¤ë¥¸ ê²ƒì„ ì‚¬ë¼)ì€ í•œêµ­ì‹œì¥ì—ì„œ ì‘ë™ ì•ˆ í•¨ (IC < 0)
       â†’ ëª¨ë©˜í…€ì´ ê°•í•˜ê²Œ ì§€ì†ë¨

v2 ì ‘ê·¼: "ì•„ì§ ëœ ì˜¬ëì§€ë§Œ ê³§ ì˜¤ë¥¼" = ë‹¤ìŒ 3ê°€ì§€ íŒ¨í„´
  1. ì´ˆê¸° ëª¨ë©˜í…€: ìµœê·¼ ë‹¨ê¸°(5ì¼)ëŠ” ì˜¬ëì§€ë§Œ ì¤‘ê¸°(30ì¼)ëŠ” ì•„ì§ â†’ ëª¨ë©˜í…€ ì´ˆê¸° ë‹¨ê³„
  2. íš¡ë³´ í›„ ëŒíŒŒ: ë³€ë™ì„± ë‚®ì•˜ëŠ”ë°(íš¡ë³´) ìµœê·¼ ê¸‰ë“± ì‹œì‘ â†’ ë¸Œë ˆì´í¬ì•„ì›ƒ
  3. ê±°ë˜ëŸ‰ ì„ í–‰: ê°€ê²©ë³´ë‹¤ ê±°ë˜ëŸ‰ì´ ë¨¼ì € ì¦ê°€ â†’ ìŠ¤ë§ˆíŠ¸ë¨¸ë‹ˆ ì„ ë§¤ìˆ˜
  4. ëª¨ë©˜í…€ ê°€ì†: ìµœê·¼ ëª¨ë©˜í…€ì´ ì´ì „ ëŒ€ë¹„ ê°€ì† â†’ ì¶”ì„¸ ê°•í™” ì´ˆê¸°

+ ì‹¤ì  ê°œì„  í•„í„°ë¥¼ ê²°í•©í•˜ì—¬ "ì§„ì§œ ì˜¤ë¥¼ ì´ìœ ê°€ ìˆëŠ”" ì¢…ëª©ë§Œ ì„ ë³„
+ 20ì˜ì—…ì¼(1ë‹¬) í¬ì›Œë“œ IC ë°±í…ŒìŠ¤íŠ¸
"""

import sys
import os
import json as _json
from pathlib import Path
import pandas as pd
import numpy as np
from dotenv import load_dotenv
import psycopg2

project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from alpha_gpt_kr.mining.operators import AlphaOperators as ops

load_dotenv()


def get_db_connection():
    return psycopg2.connect(
        host=os.getenv('DB_HOST', '192.168.0.248'),
        port=int(os.getenv('DB_PORT', 5432)),
        database=os.getenv('DB_NAME', 'marketsense'),
        user=os.getenv('DB_USER', 'yrbahn'),
        password=os.getenv('DB_PASSWORD', '1234')
    )


# â”€â”€ ë°ì´í„° ë¡œë“œ â”€â”€
print("ğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
conn = get_db_connection()

stocks_df = pd.read_sql("""
    SELECT s.id, s.ticker, s.name, s.market_cap
    FROM stocks s
    WHERE s.is_active = true
    AND s.market_cap IS NOT NULL
    AND EXISTS (
        SELECT 1 FROM price_data p
        WHERE p.stock_id = s.id
        AND p.date >= CURRENT_DATE - INTERVAL '730 days'
        LIMIT 1
    )
    ORDER BY s.market_cap DESC
    LIMIT 2000
""", conn)

stock_ids = stocks_df['id'].tolist()
stock_id_list = ', '.join(map(str, stock_ids))

ticker_name = dict(zip(stocks_df['ticker'], stocks_df['name']))
ticker_mcap = dict(zip(stocks_df['ticker'], stocks_df['market_cap']))
id_ticker = dict(zip(stocks_df['id'], stocks_df['ticker']))

price_df = pd.read_sql(f"""
    SELECT s.ticker, p.date, p.close, p.volume
    FROM price_data p
    JOIN stocks s ON p.stock_id = s.id
    WHERE p.stock_id IN ({stock_id_list})
    AND p.date >= CURRENT_DATE - INTERVAL '730 days'
    ORDER BY s.ticker, p.date
""", conn)

close = price_df.pivot(index='date', columns='ticker', values='close')
volume = price_df.pivot(index='date', columns='ticker', values='volume')
returns = close.pct_change()

# ì¬ë¬´ ì¶”ì„¸ ë°ì´í„°
print("   ì¬ë¬´ ì¶”ì„¸ ë°ì´í„° ë¡œë“œ ì¤‘...")
fin_df = pd.read_sql(f"""
    SELECT stock_id, period_end, revenue, operating_income, net_income, raw_data
    FROM financial_statements
    WHERE stock_id IN ({stock_id_list})
    ORDER BY stock_id, period_end
""", conn)
conn.close()

def _parse_raw(row):
    rd = row.get('raw_data')
    if rd is None:
        return {'quarter_type': None}
    if isinstance(rd, str):
        rd = _json.loads(rd)
    return {'quarter_type': rd.get('quarter', '')}

raw_parsed = fin_df.apply(_parse_raw, axis=1, result_type='expand')
fin_df = pd.concat([fin_df, raw_parsed], axis=1)
fin_df['ticker'] = fin_df['stock_id'].map(id_ticker)
fin_df = fin_df.dropna(subset=['ticker'])
fin_df = fin_df[fin_df['quarter_type'] != 'ì—°ê°„'].copy()
fin_df = fin_df.sort_values(['ticker', 'period_end'])

trend_records = []
for ticker, grp in fin_df.groupby('ticker'):
    grp = grp.sort_values('period_end').reset_index(drop=True)
    for i in range(len(grp)):
        row = grp.iloc[i]
        rec = {'ticker': ticker, 'period_end': row['period_end']}
        if i >= 1:
            prev = grp.iloc[i - 1]
            if prev['operating_income'] and prev['operating_income'] != 0:
                rec['oi_qoq'] = (row['operating_income'] - prev['operating_income']) / abs(prev['operating_income'])
        if i >= 3:
            yoy_prev = grp.iloc[i - 3]
            if row['period_end'].month == yoy_prev['period_end'].month:
                if yoy_prev['operating_income'] and yoy_prev['operating_income'] != 0:
                    rec['oi_yoy'] = (row['operating_income'] - yoy_prev['operating_income']) / abs(yoy_prev['operating_income'])
        if i >= 2:
            oi_vals = [grp.iloc[j]['operating_income'] for j in range(i - 2, i + 1)
                       if grp.iloc[j]['operating_income'] is not None and not np.isnan(grp.iloc[j]['operating_income'])]
            if len(oi_vals) == 3:
                rec['oi_trend'] = (oi_vals[2] - oi_vals[0]) / (abs(oi_vals[0]) + 1e-10)
        trend_records.append(rec)

trend_df = pd.DataFrame(trend_records)

_empty = pd.DataFrame(np.nan, index=close.index, columns=close.columns)
trend_vars = {}
for field in ['oi_qoq', 'oi_yoy', 'oi_trend']:
    if field not in trend_df.columns:
        continue
    pivot = trend_df.pivot_table(index='period_end', columns='ticker', values=field, aggfunc='last')
    if pivot.empty or pivot.notna().sum().sum() < 50:
        continue
    daily = pivot.reindex(close.index).ffill().reindex(columns=close.columns)
    trend_vars[f'{field}_rank'] = daily.rank(axis=1, pct=True)

oi_trend_rank = trend_vars.get('oi_trend_rank', _empty)
oi_yoy_rank = trend_vars.get('oi_yoy_rank', _empty)
oi_qoq_rank = trend_vars.get('oi_qoq_rank', _empty)

# ë°¸ë¥˜ì—ì´ì…˜ í•„í„°
print("   ë°¸ë¥˜ì—ì´ì…˜ í•„í„° ê³„ì‚° ì¤‘...")
valuation = {}
for ticker, grp in fin_df.groupby('ticker'):
    grp = grp.sort_values('period_end')
    recent = grp.tail(4)
    if len(recent) < 2:
        continue
    trailing_oi = recent['operating_income'].sum()
    trailing_ni = recent['net_income'].sum()
    mcap = ticker_mcap.get(ticker, 0)
    per = mcap / trailing_ni if mcap and mcap > 0 and trailing_ni and trailing_ni > 0 else np.nan
    valuation[ticker] = {
        'trailing_oi': trailing_oi,
        'trailing_ni': trailing_ni,
        'per': per,
    }

FILTER_PER_MAX = 50
filtered_out = set()
for ticker, v in valuation.items():
    reasons = []
    if v['trailing_ni'] is None or v['trailing_ni'] <= 0:
        reasons.append("ìˆœì´ìµ ì ì")
    elif v['per'] is not None and v['per'] > FILTER_PER_MAX:
        reasons.append(f"PER {v['per']:.1f}x")
    if v['trailing_oi'] is not None and v['trailing_oi'] <= 0:
        reasons.append("ì˜ì—…ì ì")
    if reasons:
        filtered_out.add(ticker)
no_data_tickers = set(close.columns) - set(valuation.keys())
exclude_tickers = filtered_out | no_data_tickers

print(f"âœ… {len(close.columns)}ê°œ ì¢…ëª©, {len(close)}ì¼ ë°ì´í„°")
print(f"   PER â‰¤ {FILTER_PER_MAX}x í•„í„°: {len(filtered_out)}ê°œ ì œì™¸, ì¬ë¬´ì—†ìŒ: {len(no_data_tickers)}ê°œ")


# â”€â”€ IC ê³„ì‚° â”€â”€
def compute_ic(alpha_values, close_data, forward_days=20):
    forward_return = close_data.shift(-forward_days) / close_data - 1
    ic_list = []
    for date in alpha_values.index[:-forward_days]:
        a = alpha_values.loc[date]
        r = forward_return.loc[date]
        valid = a.notna() & r.notna()
        if valid.sum() > 30:
            ic = a[valid].corr(r[valid])
            if not np.isnan(ic):
                ic_list.append(ic)
    if len(ic_list) < 10:
        return 0.0, 0.0, 0
    return np.mean(ic_list), np.std(ic_list), len(ic_list)


# Train/Test ë¶„í• 
split_idx = int(len(close) * 0.7)
train_close = close.iloc[:split_idx]
test_close = close.iloc[split_idx:]

print(f"\nğŸ“ Train/Test: {split_idx}ì¼ / {len(close) - split_idx}ì¼")
print(f"   Train: {close.index[0]} ~ {close.index[split_idx-1]}")
print(f"   Test:  {close.index[split_idx]} ~ {close.index[-1]}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v2 Catch-up Alpha: "ë§‰ ì˜¬ë¼ê°€ê¸° ì‹œì‘í•˜ëŠ”" íŒ¨í„´
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print(f"\n{'='*90}")
print(f"ğŸš€ Catch-up v2: 'ê³§ ì˜¤ë¥¼ ì¢…ëª©' ì•ŒíŒŒ ë°±í…ŒìŠ¤íŠ¸ (20ì¼ í¬ì›Œë“œ)")
print(f"   v1 êµí›ˆ: ìˆœìˆ˜ ì—­ëª¨ë©˜í…€ âŒ â†’ ì´ˆê¸°ëª¨ë©˜í…€/ëŒíŒŒ/ê°€ì† íŒ¨í„´ìœ¼ë¡œ ì¬ì„¤ê³„")
print(f"{'='*90}")

alphas = {}

# â•â•â• 1. ì´ˆê¸° ëª¨ë©˜í…€ (Early Momentum) â•â•â•
# ë‹¨ê¸°(5d)ëŠ” ì˜¬ëì§€ë§Œ ì¤‘ê¸°(30d)ëŠ” ì•„ì§ â†’ ëª¨ë©˜í…€ ì‹œì‘ ë‹¨ê³„
mom_5d = ops.ts_delta_ratio(close, 5)
mom_10d = ops.ts_delta_ratio(close, 10)
mom_20d = ops.ts_delta_ratio(close, 20)
mom_30d = ops.ts_delta_ratio(close, 30)

# ë‹¨ê¸° ëª¨ë©˜í…€ - ì¥ê¸° ëª¨ë©˜í…€ = "ìµœê·¼ì— ì‹œì‘ëœ" ëª¨ë©˜í…€
alphas['1a_ì´ˆê¸°ëª¨ë©˜í…€(5d-30d)'] = ops.normed_rank(
    ops.minus(
        ops.ts_delta_ratio(close, 5),
        ops.ts_delta_ratio(close, 30)
    )
)

# ë‹¨ê¸° ìƒìŠ¹ + ì¥ê¸° ì•„ì§ ë‚®ì€ ìœ„ì¹˜ â†’ "ë°”ë‹¥ì—ì„œ ë§‰ ì˜¬ë¼ì˜¤ëŠ”"
alphas['1b_ë°”ë‹¥íƒˆì¶œ(5dâ†‘+30dì €ìœ„ì¹˜)'] = ops.normed_rank(
    ops.cwise_mul(
        ops.ts_delta_ratio(close, 5),
        ops.neg(ops.ts_maxmin_scale(close, 30))
    )
)

# ì´ˆê¸° ëª¨ë©˜í…€ + ì‹¤ì  ê°œì„ 
alphas['1c_ì´ˆê¸°ëª¨ë©˜í…€Ã—ì‹¤ì '] = ops.normed_rank(
    ops.cwise_mul(
        ops.minus(ops.ts_delta_ratio(close, 5), ops.ts_delta_ratio(close, 25)),
        oi_yoy_rank
    )
)

# â•â•â• 2. íš¡ë³´ í›„ ëŒíŒŒ (Breakout from Consolidation) â•â•â•
# ê³¼ê±° ë³€ë™ì„± ë‚®ì•˜ëŠ”ë°(íš¡ë³´) + ìµœê·¼ ìƒìŠ¹ ì‹œì‘
past_vol = ops.ts_std(returns, 30)  # ê³¼ê±° 30ì¼ ë³€ë™ì„±
recent_move = ops.ts_delta_ratio(close, 5)  # ìµœê·¼ 5ì¼ ì›€ì§ì„

alphas['2a_íš¡ë³´í›„ëŒíŒŒ'] = ops.normed_rank(
    ops.cwise_mul(
        ops.neg(past_vol),  # ë³€ë™ì„± ë‚®ì•˜ë˜ (íš¡ë³´)
        recent_move          # Ã— ìµœê·¼ ìƒìŠ¹
    )
)

# íš¡ë³´ í›„ ëŒíŒŒ + ê±°ë˜ëŸ‰ í™•ì¸
alphas['2b_ëŒíŒŒÃ—ê±°ë˜ëŸ‰í­ì¦'] = ops.normed_rank(
    ops.cwise_mul(
        ops.cwise_mul(
            ops.neg(ops.ts_std(returns, 20)),
            ops.ts_delta_ratio(close, 5)
        ),
        ops.div(ops.ts_mean(volume, 3), ops.ts_mean(volume, 20))  # 3ì¼ ê±°ë˜ëŸ‰ / 20ì¼ í‰ê· 
    )
)

# íš¡ë³´ í›„ ëŒíŒŒ + ì‹¤ì 
alphas['2c_ëŒíŒŒÃ—ì‹¤ì ê°œì„ '] = ops.normed_rank(
    ops.cwise_mul(
        ops.cwise_mul(
            ops.neg(ops.ts_std(returns, 25)),
            ops.ts_delta_ratio(close, 7)
        ),
        oi_yoy_rank
    )
)

# â•â•â• 3. ê±°ë˜ëŸ‰ ì„ í–‰ (Volume Leads Price) â•â•â•
# ê±°ë˜ëŸ‰ì´ ë¨¼ì € ì¦ê°€ â†’ ê°€ê²© ì•„ì§ ì•ˆ ì˜¬ëì§€ë§Œ ê³§ ì˜¤ë¥¼ ì‹ í˜¸
vol_momentum = ops.ts_delta_ratio(volume, 10)  # ê±°ë˜ëŸ‰ ì¦ê°€ìœ¨
price_momentum = ops.ts_delta_ratio(close, 10)  # ê°€ê²© ë³€í™”ìœ¨

# ê±°ë˜ëŸ‰â†‘ ê°€ê²© ì•„ì§ â†’ ê´´ë¦¬
alphas['3a_ê±°ë˜ëŸ‰ì„ í–‰'] = ops.normed_rank(
    ops.minus(
        ops.normed_rank(ops.ts_delta_ratio(volume, 10)),
        ops.normed_rank(ops.ts_delta_ratio(close, 10))
    )
)

# ê±°ë˜ëŸ‰ ìµœê·¼ ê¸‰ì¦ + ê°€ê²© ì•„ì§ ì €ìœ„ì¹˜
alphas['3b_ê±°ë˜ëŸ‰ê¸‰ì¦Ã—ê°€ê²©ì €ìœ„ì¹˜'] = ops.normed_rank(
    ops.cwise_mul(
        ops.div(ops.ts_mean(volume, 5), ops.ts_mean(volume, 30)),
        ops.neg(ops.ts_maxmin_scale(close, 20))
    )
)

# ê±°ë˜ëŸ‰ ì„ í–‰ + ì‹¤ì  í™•ì¸
alphas['3c_ê±°ë˜ëŸ‰ì„ í–‰Ã—ì‹¤ì '] = ops.normed_rank(
    ops.cwise_mul(
        ops.minus(
            ops.normed_rank(ops.ts_delta_ratio(volume, 10)),
            ops.normed_rank(ops.ts_delta_ratio(close, 10))
        ),
        oi_yoy_rank
    )
)

# â•â•â• 4. ëª¨ë©˜í…€ ê°€ì† (Momentum Acceleration) â•â•â•
# ìµœê·¼ ëª¨ë©˜í…€ì´ ì´ì „ë³´ë‹¤ ê°•í•´ì§€ëŠ” â†’ ì¶”ì„¸ ì´ˆê¸°/ê°€ì† ë‹¨ê³„
alphas['4a_ëª¨ë©˜í…€ê°€ì†'] = ops.normed_rank(
    ops.minus(
        ops.ts_delta_ratio(close, 10),   # ìµœê·¼ 10ì¼ ìˆ˜ìµë¥ 
        ops.ts_delta_ratio(close.shift(10), 10)  # 10~20ì¼ì „ ìˆ˜ìµë¥ 
    )
)

# ê°€ì† + ê±°ë˜ëŸ‰ ë™ë°˜
alphas['4b_ê°€ì†Ã—ê±°ë˜ëŸ‰ë™ë°˜'] = ops.normed_rank(
    ops.cwise_mul(
        ops.minus(
            ops.ts_delta_ratio(close, 10),
            ops.ts_delta_ratio(close.shift(10), 10)
        ),
        ops.div(ops.ts_mean(volume, 5), ops.ts_mean(volume, 20))
    )
)

# ê°€ì† + ì‹¤ì 
alphas['4c_ê°€ì†Ã—ì‹¤ì ê°œì„ '] = ops.normed_rank(
    ops.cwise_mul(
        ops.minus(
            ops.ts_delta_ratio(close, 10),
            ops.ts_delta_ratio(close.shift(10), 10)
        ),
        oi_yoy_rank
    )
)

# â•â•â• 5. ë³µí•©í˜• (Best Combinations) â•â•â•
# ì´ˆê¸° ëª¨ë©˜í…€ + ê±°ë˜ëŸ‰ í™•ì¸ + ì‹¤ì 
alphas['5a_ì´ˆê¸°ëª¨ë©˜í…€Ã—ê±°ë˜ëŸ‰Ã—ì‹¤ì '] = ops.normed_rank(
    ops.cwise_mul(
        ops.cwise_mul(
            ops.minus(ops.ts_delta_ratio(close, 5), ops.ts_delta_ratio(close, 25)),
            ops.div(ops.ts_mean(volume, 5), ops.ts_mean(volume, 20))
        ),
        oi_yoy_rank
    )
)

# ëŒíŒŒ + ê±°ë˜ëŸ‰ + ì‹¤ì  3íŒ©í„°
alphas['5b_ëŒíŒŒÃ—ê±°ë˜ëŸ‰Ã—ì‹¤ì '] = ops.normed_rank(
    ops.cwise_mul(
        ops.cwise_mul(
            ops.cwise_mul(
                ops.neg(ops.ts_std(returns, 20)),
                ops.ts_delta_ratio(close, 5)
            ),
            ops.div(ops.ts_mean(volume, 3), ops.ts_mean(volume, 20))
        ),
        oi_yoy_rank
    )
)

# ëª¨ë©˜í…€ ê°€ì† + ê±°ë˜ëŸ‰ + ì‹¤ì 
alphas['5c_ê°€ì†Ã—ê±°ë˜ëŸ‰Ã—ì‹¤ì '] = ops.normed_rank(
    ops.cwise_mul(
        ops.cwise_mul(
            ops.minus(ops.ts_delta_ratio(close, 10), ops.ts_delta_ratio(close.shift(10), 10)),
            ops.div(ops.ts_mean(volume, 5), ops.ts_mean(volume, 20))
        ),
        oi_yoy_rank
    )
)

# â•â•â• 6. ê¸°ì¡´ v3 ê°œì„ í˜• (20ì¼ ìµœì í™”) â•â•â•
# v3ë¥¼ 20ì¼ì— ë§ì¶° ì¬ì¡°ì •
alphas['6a_v3_20dìµœì í™”'] = ops.normed_rank(
    ops.cwise_mul(
        ops.cwise_mul(
            ops.ts_delta_ratio(close, 20),
            ops.div(ops.ts_median(volume, 10), ops.ts_std(volume, 15))
        ),
        ops.ts_maxmin_scale(close, 25)
    )
)

# v3 + ì‹¤ì  (20ì¼ìš©)
alphas['6b_v3_20dÃ—ì‹¤ì '] = ops.normed_rank(
    ops.cwise_mul(
        ops.cwise_mul(
            ops.cwise_mul(
                ops.ts_delta_ratio(close, 20),
                ops.div(ops.ts_median(volume, 10), ops.ts_std(volume, 15))
            ),
            ops.ts_maxmin_scale(close, 25)
        ),
        oi_yoy_rank
    )
)

# â•â•â• ë¹„êµìš© â•â•â•
alphas['REF_v3ëª¨ë©˜í…€'] = ops.normed_rank(
    ops.cwise_mul(
        ops.cwise_mul(
            ops.ts_delta_ratio(close, 25),
            ops.div(ops.ts_median(volume, 10), ops.ts_std(volume, 15))
        ),
        ops.ts_maxmin_scale(close, 28)
    )
)

alphas['REF_v6ì‹¤ì '] = ops.normed_rank(
    ops.add(ops.add(oi_trend_rank, oi_yoy_rank), oi_qoq_rank)
)

alphas['REF_ì•™ìƒë¸”v3v6'] = ops.normed_rank(
    alphas['REF_v3ëª¨ë©˜í…€'] * 0.5 +
    ops.normed_rank(ops.add(ops.add(oi_trend_rank, oi_yoy_rank), oi_qoq_rank)).fillna(0.5) * 0.5
)


# â”€â”€ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰ â”€â”€
print(f"\n{'ìˆœë²ˆ':>4} {'ì•ŒíŒŒëª…':<30} {'Train IC':>10} {'Test IC':>10} {'IR':>6} {'íŒì •':>4}")
print(f"{'-'*70}")

results = []
for name, alpha in alphas.items():
    train_ic, train_std, train_n = compute_ic(alpha.iloc[:split_idx], train_close)
    test_ic, test_std, test_n = compute_ic(alpha.iloc[split_idx:], test_close)
    ir = test_ic / test_std if test_std > 0 else 0

    status = "âœ…" if test_ic > 0.02 else ("âš ï¸" if test_ic > 0 else "âŒ")
    print(f"  {len(results)+1:>2}. {name:<30} {train_ic:>+.4f}    {test_ic:>+.4f}  {ir:>+.2f}   {status}")

    results.append({
        'name': name,
        'alpha': alpha,
        'train_ic': train_ic,
        'test_ic': test_ic,
        'ir': ir,
    })

# â”€â”€ ê²°ê³¼ ë¶„ì„ â”€â”€
results.sort(key=lambda x: x['test_ic'], reverse=True)

print(f"\n{'='*90}")
print(f"ğŸ“Š Test IC ê¸°ì¤€ ìˆœìœ„ (20ì¼ í¬ì›Œë“œ)")
print(f"{'='*90}")
for i, r in enumerate(results, 1):
    marker = " ğŸ†" if i == 1 else (" â­" if i <= 3 else "")
    ref = " [REF]" if r['name'].startswith('REF_') else ""
    print(f"  {i:>2}. {r['name']:<30}  Test IC: {r['test_ic']:>+.4f}  Train: {r['train_ic']:>+.4f}  IR: {r['ir']:>+.2f}{marker}{ref}")

# â”€â”€ ìƒìœ„ ì•ŒíŒŒë¡œ ì¢…ëª© ì„ ì • â”€â”€
# REF ì œì™¸í•œ best catch-up ì•ŒíŒŒ ì°¾ê¸°
non_ref = [r for r in results if not r['name'].startswith('REF_') and r['test_ic'] > 0]

if non_ref:
    best = non_ref[0]
    print(f"\n{'='*90}")
    print(f"ğŸ† ìµœì  Catch-up ì•ŒíŒŒ: {best['name']}")
    print(f"   Train IC: {best['train_ic']:+.4f} / Test IC: {best['test_ic']:+.4f} / IR: {best['ir']:+.2f}")
    print(f"{'='*90}")

    # ìµœì‹  ë‚ ì§œ ê¸°ì¤€ ì¢…ëª© ì„ ì •
    latest_date = close.index[-1]
    alpha_scores = best['alpha'].loc[latest_date].dropna().sort_values(ascending=False)

    # ë°¸ë¥˜ì—ì´ì…˜ í•„í„°
    filtered_scores = alpha_scores[~alpha_scores.index.isin(exclude_tickers)]

    print(f"\nğŸ“‹ Catch-up ìƒìœ„ 10ì¢…ëª© (ê¸°ì¤€ì¼: {latest_date})")
    print(f"   í•„í„°: PER â‰¤ {FILTER_PER_MAX}x, ì˜ì—…í‘ì, ìˆœì´ìµí‘ì")
    print(f"   ìœ ë‹ˆë²„ìŠ¤: {len(alpha_scores)}ì¢…ëª© â†’ í•„í„° í†µê³¼ {len(filtered_scores)}ì¢…ëª©")
    print(f"\n{'ìˆœìœ„':>4} {'ì¢…ëª©ì½”ë“œ':<10} {'ì¢…ëª©ëª…':<16} {'Catch-up':>10} {'20dìˆ˜ìµë¥ ':>10} {'PER':>6} {'NI(ì–µ)':>8}")
    print(f"{'-'*75}")

    for i, (ticker, score) in enumerate(filtered_scores.head(10).items(), 1):
        name = ticker_name.get(ticker, '?')
        price = close.loc[latest_date, ticker]
        # ìµœê·¼ 20ì¼ ìˆ˜ìµë¥ 
        if len(close) > 20:
            ret_20d = (close.loc[latest_date, ticker] / close.iloc[-20][ticker] - 1) * 100
        else:
            ret_20d = 0
        v = valuation.get(ticker, {})
        per = v.get('per', np.nan)
        ni = v.get('trailing_ni', 0)
        ni_ì–µ = ni / 1e8 if ni else 0
        per_s = f"{per:.1f}x" if per and not np.isnan(per) else "  -"
        print(f"  {i:>2}. {ticker:<10} {name:<16} {score:.4f}    {ret_20d:>+.1f}%  {per_s:>6} {ni_ì–µ:>7,.0f}ì–µ")

    # ì•™ìƒë¸” ì‹œë„: best catch-up + v3 + v6
    print(f"\n{'='*90}")
    print(f"ğŸ”— ì•™ìƒë¸”: Catch-up + ê¸°ì¡´ ì•ŒíŒŒ")
    print(f"{'='*90}")

    v3 = alphas['REF_v3ëª¨ë©˜í…€']
    v6 = alphas['REF_v6ì‹¤ì '].fillna(0.5)
    catchup = best['alpha']

    weights_to_test = [
        ('Catch 33% + v3 33% + v6 33%', 0.33, 0.33, 0.34),
        ('Catch 50% + v3 25% + v6 25%', 0.50, 0.25, 0.25),
        ('Catch 25% + v3 25% + v6 50%', 0.25, 0.25, 0.50),
        ('Catch 20% + v3 40% + v6 40%', 0.20, 0.40, 0.40),
    ]

    print(f"\n{'êµ¬ì„±':<35} {'Train IC':>10} {'Test IC':>10} {'IR':>6}")
    print(f"{'-'*65}")

    for label, wc, w3, w6 in weights_to_test:
        ens = ops.normed_rank(catchup * wc + v3 * w3 + v6 * w6)
        train_ic, _, _ = compute_ic(ens.iloc[:split_idx], train_close)
        test_ic, test_std, _ = compute_ic(ens.iloc[split_idx:], test_close)
        ir = test_ic / test_std if test_std > 0 else 0
        print(f"  {label:<35} {train_ic:>+.4f}    {test_ic:>+.4f}  {ir:>+.2f}")

else:
    print(f"\nâš ï¸  ì–‘ì˜ Test ICë¥¼ ê°€ì§„ Catch-up ì•ŒíŒŒê°€ ì—†ìŠµë‹ˆë‹¤.")
    print(f"   â†’ í˜„ì¬ ì‹œì¥ì€ ê°•í•œ ëª¨ë©˜í…€ ì¥ì„¸ë¡œ, 'ëœ ì˜¤ë¥¸ ê²ƒì„ ì‚¬ëŠ”' ì „ëµ ìì²´ê°€ ë¶ˆë¦¬í•©ë‹ˆë‹¤.")
    print(f"   â†’ ê¸°ì¡´ v3(ëª¨ë©˜í…€)+v6(ì‹¤ì ) ì•™ìƒë¸”ì„ ìœ ì§€í•˜ëŠ” ê²ƒì´ ìµœì„ ì…ë‹ˆë‹¤.")

    # ëŒ€ì•ˆ: ë¹„êµì  ë‚˜ì€ ê²ƒë“¤ í‘œì‹œ
    print(f"\n   ë¹„êµì  ICê°€ ë†’ì€ ì•ŒíŒŒ (REF ì œì™¸):")
    non_ref_all = [r for r in results if not r['name'].startswith('REF_')]
    for r in non_ref_all[:5]:
        print(f"     {r['name']:<30}  Test IC: {r['test_ic']:>+.4f}")

print(f"\n{'='*90}")
print(f"ğŸ’¡ ê²°ë¡  ë° í•´ì„")
print(f"{'='*90}")
print(f"   v1 ì—­ëª¨ë©˜í…€: 'ëœ ì˜¤ë¥¸ ê²ƒì„ ì‚¬ë¼' â†’ IC < 0 (ì‹¤íŒ¨)")
print(f"   v2 ì´ˆê¸°ëª¨ë©˜í…€: 'ë§‰ ì˜¬ë¼ê°€ê¸° ì‹œì‘í•˜ëŠ” ê²ƒ' â†’ ìœ„ ê²°ê³¼ í™•ì¸")
print(f"   v2 ëŒíŒŒí˜•: 'íš¡ë³´ í›„ ëŒíŒŒ ì‹œì‘' â†’ ìœ„ ê²°ê³¼ í™•ì¸")
print(f"   v2 ê°€ì†í˜•: 'ëª¨ë©˜í…€ ê°€ì†ë˜ëŠ” ê²ƒ' â†’ ìœ„ ê²°ê³¼ í™•ì¸")
print(f"   â†’ 20ì˜ì—…ì¼(ì•½ 1ë‹¬) ë¦¬ë°¸ëŸ°ì‹± ì „ëµì— ì í•©í•œ ì•ŒíŒŒ ì„ ì •")
