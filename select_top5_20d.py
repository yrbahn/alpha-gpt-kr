#!/usr/bin/env python3
"""
3íŒ©í„° ì•™ìƒë¸” ìƒìœ„ ì¢…ëª© ì„ ì • (20ì¼ ë¦¬ë°¸ëŸ°ì‹±)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

v7 ëª¨ë©˜í…€Ã—ì‹¤ì  (25%) + v3 ê°€ê²© (25%) + v6 ì¬ë¬´ì¶”ì„¸ (50%)
Test IC: +0.0570 / IR: 0.92 (20-day forward)

ê° íŒ©í„°:
  v7: 20ì¼ ëª¨ë©˜í…€ Ã— ê±°ë˜ëŸ‰ ì•ˆì •ì„± Ã— 25ì¼ ë ˆì¸ì§€ Ã— ì‹¤ì  YoY ê°œì„ 
  v3: 25ì¼ ëª¨ë©˜í…€ Ã— ê±°ë˜ëŸ‰ ì•ˆì •ì„± Ã— 28ì¼ ë ˆì¸ì§€ (Test IC 0.0374)
  v6: ì˜ì—…ì´ìµ 3Qì¶”ì„¸ + YoY + QoQ ë­í‚¹ í•©ì‚° (Test IC 0.0592)

í•„í„°: PER â‰¤ 50x, ì˜ì—…í‘ì, ìˆœì´ìµí‘ì
"""

import sys
import os
import json as _json
from pathlib import Path
import pandas as pd
import numpy as np
from dotenv import load_dotenv
import psycopg2

project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from alpha_gpt_kr.mining.operators import AlphaOperators as ops

load_dotenv()


def get_db_connection():
    return psycopg2.connect(
        host=os.getenv('DB_HOST', '192.168.0.248'),
        port=int(os.getenv('DB_PORT', 5432)),
        database=os.getenv('DB_NAME', 'marketsense'),
        user=os.getenv('DB_USER', 'yrbahn'),
        password=os.getenv('DB_PASSWORD', '1234')
    )


# â”€â”€ ë°ì´í„° ë¡œë“œ â”€â”€
print("ğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
conn = get_db_connection()

stocks_df = pd.read_sql("""
    SELECT s.id, s.ticker, s.name, s.market_cap
    FROM stocks s
    WHERE s.is_active = true
    AND s.market_cap IS NOT NULL
    AND EXISTS (
        SELECT 1 FROM price_data p
        WHERE p.stock_id = s.id
        AND p.date >= CURRENT_DATE - INTERVAL '730 days'
        LIMIT 1
    )
    ORDER BY s.market_cap DESC
    LIMIT 2000
""", conn)

stock_ids = stocks_df['id'].tolist()
stock_id_list = ', '.join(map(str, stock_ids))

ticker_name = dict(zip(stocks_df['ticker'], stocks_df['name']))
ticker_mcap = dict(zip(stocks_df['ticker'], stocks_df['market_cap']))
id_ticker = dict(zip(stocks_df['id'], stocks_df['ticker']))

price_df = pd.read_sql(f"""
    SELECT s.ticker, p.date, p.close, p.volume
    FROM price_data p
    JOIN stocks s ON p.stock_id = s.id
    WHERE p.stock_id IN ({stock_id_list})
    AND p.date >= CURRENT_DATE - INTERVAL '730 days'
    ORDER BY s.ticker, p.date
""", conn)

close = price_df.pivot(index='date', columns='ticker', values='close')
volume = price_df.pivot(index='date', columns='ticker', values='volume')
returns = close.pct_change()

# ì¬ë¬´ ì¶”ì„¸ ë°ì´í„°
print("   ì¬ë¬´ ì¶”ì„¸ ë°ì´í„° ë¡œë“œ ì¤‘...")
fin_df = pd.read_sql(f"""
    SELECT stock_id, period_end, revenue, operating_income, net_income, raw_data
    FROM financial_statements
    WHERE stock_id IN ({stock_id_list})
    ORDER BY stock_id, period_end
""", conn)
conn.close()

def _parse_raw(row):
    rd = row.get('raw_data')
    if rd is None:
        return {'quarter_type': None}
    if isinstance(rd, str):
        rd = _json.loads(rd)
    return {'quarter_type': rd.get('quarter', '')}

raw_parsed = fin_df.apply(_parse_raw, axis=1, result_type='expand')
fin_df = pd.concat([fin_df, raw_parsed], axis=1)
fin_df['ticker'] = fin_df['stock_id'].map(id_ticker)
fin_df = fin_df.dropna(subset=['ticker'])
fin_df = fin_df[fin_df['quarter_type'] != 'ì—°ê°„'].copy()
fin_df = fin_df.sort_values(['ticker', 'period_end'])

# â”€â”€ ë°¸ë¥˜ì—ì´ì…˜ í•„í„°ìš© â”€â”€
print("   ë°¸ë¥˜ì—ì´ì…˜ í•„í„° ê³„ì‚° ì¤‘...")
valuation = {}
for ticker, grp in fin_df.groupby('ticker'):
    grp = grp.sort_values('period_end')
    recent = grp.tail(4)
    if len(recent) < 2:
        continue
    trailing_rev = recent['revenue'].sum()
    trailing_oi = recent['operating_income'].sum()
    trailing_ni = recent['net_income'].sum()
    mcap = ticker_mcap.get(ticker, 0)
    if mcap and mcap > 0 and trailing_ni and trailing_ni > 0:
        per = mcap / trailing_ni
    else:
        per = np.nan
    valuation[ticker] = {
        'trailing_rev': trailing_rev,
        'trailing_oi': trailing_oi,
        'trailing_ni': trailing_ni,
        'per': per,
    }

FILTER_PER_MAX = 50

filtered_out = set()
for ticker, v in valuation.items():
    reasons = []
    if v['trailing_ni'] is None or v['trailing_ni'] <= 0:
        reasons.append("ìˆœì´ìµ ì ì")
    elif v['per'] is not None and v['per'] > FILTER_PER_MAX:
        reasons.append(f"PER {v['per']:.1f}x")
    if v['trailing_oi'] is not None and v['trailing_oi'] <= 0:
        reasons.append("ì˜ì—…ì ì")
    if reasons:
        filtered_out.add(ticker)

tickers_with_valuation = set(valuation.keys())
no_data_tickers = set(close.columns) - tickers_with_valuation
exclude_tickers = filtered_out | no_data_tickers

print(f"   í•„í„° ì¡°ê±´: PER â‰¤ {FILTER_PER_MAX}x, ì˜ì—…ì´ìµ í‘ì, ìˆœì´ìµ í‘ì")
print(f"   ë°¸ë¥˜ í•„í„° ì œì™¸: {len(filtered_out)}ê°œ, ì¬ë¬´ë°ì´í„° ì—†ìŒ: {len(no_data_tickers)}ê°œ")

# â”€â”€ QoQ / YoY / 3ë¶„ê¸° ì¶”ì„¸ â”€â”€
trend_records = []
for ticker, grp in fin_df.groupby('ticker'):
    grp = grp.sort_values('period_end').reset_index(drop=True)
    for i in range(len(grp)):
        row = grp.iloc[i]
        rec = {'ticker': ticker, 'period_end': row['period_end']}

        if i >= 1:
            prev = grp.iloc[i - 1]
            if prev['operating_income'] and prev['operating_income'] != 0:
                rec['oi_qoq'] = (row['operating_income'] - prev['operating_income']) / abs(prev['operating_income'])

        if i >= 3:
            yoy_prev = grp.iloc[i - 3]
            if row['period_end'].month == yoy_prev['period_end'].month:
                if yoy_prev['operating_income'] and yoy_prev['operating_income'] != 0:
                    rec['oi_yoy'] = (row['operating_income'] - yoy_prev['operating_income']) / abs(yoy_prev['operating_income'])

        if i >= 2:
            oi_vals = [grp.iloc[j]['operating_income'] for j in range(i - 2, i + 1)
                       if grp.iloc[j]['operating_income'] is not None and not np.isnan(grp.iloc[j]['operating_income'])]
            if len(oi_vals) == 3:
                rec['oi_trend'] = (oi_vals[2] - oi_vals[0]) / (abs(oi_vals[0]) + 1e-10)

        trend_records.append(rec)

trend_df = pd.DataFrame(trend_records)

_empty = pd.DataFrame(np.nan, index=close.index, columns=close.columns)
trend_vars = {}
for field in ['oi_qoq', 'oi_yoy', 'oi_trend']:
    if field not in trend_df.columns:
        continue
    pivot = trend_df.pivot_table(index='period_end', columns='ticker', values=field, aggfunc='last')
    if pivot.empty or pivot.notna().sum().sum() < 50:
        continue
    daily = pivot.reindex(close.index).ffill().reindex(columns=close.columns)
    trend_vars[f'{field}_rank'] = daily.rank(axis=1, pct=True)

oi_trend_rank = trend_vars.get('oi_trend_rank', _empty)
oi_yoy_rank = trend_vars.get('oi_yoy_rank', _empty)
oi_qoq_rank = trend_vars.get('oi_qoq_rank', _empty)

print(f"âœ… {len(close.columns)}ê°œ ì¢…ëª©, {len(close)}ì¼ ë°ì´í„°")
print(f"   ìµœì‹  ë‚ ì§œ: {close.index[-1]}")
print(f"   ì¬ë¬´ ì¶”ì„¸: {list(trend_vars.keys())}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3íŒ©í„° ì•ŒíŒŒ ê³„ì‚°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# â”€â”€ v7: 20ì¼ ëª¨ë©˜í…€ Ã— ê±°ë˜ëŸ‰ ì•ˆì •ì„± Ã— 25ì¼ ë ˆì¸ì§€ Ã— ì‹¤ì  YoY â”€â”€
# ê°€ê²© ëª¨ë©˜í…€ + ì‹¤ì  ê°œì„ ì´ ë™ì‹œì— ë‚˜íƒ€ë‚˜ëŠ” ì¢…ëª© (20d ìµœì í™”)
v7_alpha = ops.normed_rank(
    ops.cwise_mul(
        ops.cwise_mul(
            ops.cwise_mul(
                ops.ts_delta_ratio(close, 20),
                ops.div(ops.ts_median(volume, 10), ops.ts_std(volume, 15))
            ),
            ops.ts_maxmin_scale(close, 25)
        ),
        oi_yoy_rank
    )
)

# â”€â”€ v3: 25ì¼ ëª¨ë©˜í…€ Ã— ê±°ë˜ëŸ‰ ì•ˆì •ì„± Ã— 28ì¼ ë ˆì¸ì§€ â”€â”€
v3_alpha = ops.normed_rank(
    ops.cwise_mul(
        ops.cwise_mul(
            ops.ts_delta_ratio(close, 25),
            ops.div(ops.ts_median(volume, 10), ops.ts_std(volume, 15))
        ),
        ops.ts_maxmin_scale(close, 28)
    )
)

# â”€â”€ v6: ì˜ì—…ì´ìµ ì¶”ì„¸ + YoY + QoQ ë­í‚¹ í•©ì‚° â”€â”€
v6_alpha = ops.normed_rank(
    ops.add(ops.add(oi_trend_rank, oi_yoy_rank), oi_qoq_rank)
)

# â”€â”€ 3íŒ©í„° ì•™ìƒë¸”: v7 25% + v3 25% + v6 50% â”€â”€
W_V7 = 0.25   # ëª¨ë©˜í…€Ã—ì‹¤ì  (catch-up ì„±ê²©)
W_V3 = 0.25   # ìˆœìˆ˜ ê°€ê²© ëª¨ë©˜í…€
W_V6 = 0.50   # ì¬ë¬´ì¶”ì„¸ (ê°€ì¥ ê°•ë ¥)

v6_filled = v6_alpha.fillna(0.5)
v7_filled = v7_alpha.fillna(0.5)

ensemble = ops.normed_rank(
    v7_filled * W_V7 + v3_alpha * W_V3 + v6_filled * W_V6
)

# â”€â”€ ìµœì‹  ë‚ ì§œ ê¸°ì¤€ â”€â”€
latest_date = ensemble.index[-1]
all_scores = ensemble.loc[latest_date].dropna().sort_values(ascending=False)

# ë°¸ë¥˜ì—ì´ì…˜ í•„í„° ì ìš©
filtered_scores = all_scores[~all_scores.index.isin(exclude_tickers)]

# â”€â”€ ì¶”ê°€ ì •ë³´: ìµœê·¼ 20ì¼ ìˆ˜ìµë¥ , ëª¨ë©˜í…€ ê°€ì†ë„ â”€â”€
if len(close) > 20:
    ret_20d = (close.iloc[-1] / close.iloc[-20] - 1) * 100
else:
    ret_20d = pd.Series(0, index=close.columns)

# ëª¨ë©˜í…€ ê°€ì†: ìµœê·¼ 10ì¼ ìˆ˜ìµë¥  - ì´ì „ 10ì¼ ìˆ˜ìµë¥ 
if len(close) > 20:
    mom_recent = close.iloc[-1] / close.iloc[-10] - 1
    mom_prev = close.iloc[-10] / close.iloc[-20] - 1
    mom_accel = (mom_recent - mom_prev) * 100
else:
    mom_accel = pd.Series(0, index=close.columns)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ê²°ê³¼ ì¶œë ¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print(f"\n{'='*100}")
print(f"ğŸ† 3íŒ©í„° ì•™ìƒë¸” ìƒìœ„ ì¢…ëª© (ê¸°ì¤€ì¼: {latest_date})")
print(f"   v7 ëª¨ë©˜í…€Ã—ì‹¤ì  ({W_V7:.0%}) + v3 ê°€ê²© ({W_V3:.0%}) + v6 ì¬ë¬´ì¶”ì„¸ ({W_V6:.0%})")
print(f"   Test IC: +0.0570 / IR: 0.92 (20-day forward)")
print(f"   í•„í„°: PER â‰¤ {FILTER_PER_MAX}x, ì˜ì—…í‘ì, ìˆœì´ìµí‘ì")
print(f"   ìœ ë‹ˆë²„ìŠ¤: {len(all_scores)}ì¢…ëª© â†’ í•„í„° í†µê³¼ {len(filtered_scores)}ì¢…ëª©")
print(f"{'='*100}")
print(f"{'ìˆœìœ„':>4} {'ì¢…ëª©ì½”ë“œ':<10} {'ì¢…ëª©ëª…':<14} {'ì•™ìƒë¸”':>8} {'v7':>6} {'v3':>6} {'v6':>6} {'í˜„ì¬ê°€':>12} {'20dìˆ˜ìµë¥ ':>10} {'ê°€ì†ë„':>8} {'PER':>6} {'NI(ì–µ)':>8}")
print(f"{'-'*110}")

for i, (ticker, score) in enumerate(filtered_scores.head(15).items(), 1):
    name = ticker_name.get(ticker, '?')
    v7_s = v7_alpha.loc[latest_date, ticker] if ticker in v7_alpha.columns else np.nan
    v3_s = v3_alpha.loc[latest_date, ticker] if ticker in v3_alpha.columns else np.nan
    v6_s = v6_alpha.loc[latest_date, ticker] if ticker in v6_alpha.columns else np.nan
    price = close.loc[latest_date, ticker]
    ret = ret_20d.get(ticker, 0)
    accel = mom_accel.get(ticker, 0)
    v = valuation.get(ticker, {})
    per = v.get('per', np.nan)
    ni = v.get('trailing_ni', 0)
    ni_ì–µ = ni / 1e8 if ni else 0
    per_s = f"{per:.1f}x" if per and not np.isnan(per) else "  -"
    v7_str = f"{v7_s:.3f}" if not np.isnan(v7_s) else "  -  "
    v6_str = f"{v6_s:.3f}" if not np.isnan(v6_s) else "  -  "

    # ê°€ì†ë„ í‘œì‹œ: ì–‘ìˆ˜ë©´ â†‘, ìŒìˆ˜ë©´ â†“
    accel_mark = "â†‘" if accel > 1 else ("â†“" if accel < -1 else "â†’")

    print(f"  {i:>2}. {ticker:<10} {name:<14} {score:.4f} {v7_str}  {v3_s:.3f}  {v6_str} {price:>12,.0f}ì› {ret:>+7.1f}%  {accel:>+5.1f}{accel_mark} {per_s:>6} {ni_ì–µ:>7,.0f}ì–µ")

# â”€â”€ í•„í„°ë¡œ ì œì™¸ëœ ìƒìœ„ ì¢…ëª© â”€â”€
excluded_top = all_scores[all_scores.index.isin(filtered_out)].head(5)
if not excluded_top.empty:
    print(f"\nâš ï¸  í•„í„°ë¡œ ì œì™¸ëœ ê³ ì ìˆ˜ ì¢…ëª©:")
    for ticker, score in excluded_top.items():
        name = ticker_name.get(ticker, '?')
        v = valuation.get(ticker, {})
        per = v.get('per', np.nan)
        ni = v.get('trailing_ni', 0)
        ni_ì–µ = ni / 1e8 if ni else 0
        per_s = f"PER {per:.1f}x" if per and not np.isnan(per) else "PER N/A"
        ni_s = f"NI {ni_ì–µ:,.0f}ì–µ" if ni and ni > 0 else "ìˆœì´ìµì ì"
        oi = v.get('trailing_oi', 0)
        oi_s = "" if oi and oi > 0 else " ì˜ì—…ì ì"
        print(f"     {ticker:<10} {name:<14} ì ìˆ˜ {score:.4f}  {per_s}  {ni_s}{oi_s}")

# â”€â”€ í•˜ìœ„ 5ì¢…ëª© â”€â”€
print(f"\n{'='*100}")
print(f"ğŸ“‰ í•˜ìœ„ 5ì¢…ëª© (ìˆ í›„ë³´, í•„í„° í†µê³¼)")
print(f"{'='*100}")
print(f"{'ìˆœìœ„':>4} {'ì¢…ëª©ì½”ë“œ':<10} {'ì¢…ëª©ëª…':<14} {'ì•™ìƒë¸”':>8} {'v7':>6} {'v3':>6} {'v6':>6} {'í˜„ì¬ê°€':>12} {'20dìˆ˜ìµë¥ ':>10} {'PER':>6} {'NI(ì–µ)':>8}")
print(f"{'-'*100}")

for i, (ticker, score) in enumerate(filtered_scores.tail(5).items(), 1):
    name = ticker_name.get(ticker, '?')
    v7_s = v7_alpha.loc[latest_date, ticker] if ticker in v7_alpha.columns else np.nan
    v3_s = v3_alpha.loc[latest_date, ticker] if ticker in v3_alpha.columns else np.nan
    v6_s = v6_alpha.loc[latest_date, ticker] if ticker in v6_alpha.columns else np.nan
    price = close.loc[latest_date, ticker]
    ret = ret_20d.get(ticker, 0)
    v = valuation.get(ticker, {})
    per = v.get('per', np.nan)
    ni = v.get('trailing_ni', 0)
    ni_ì–µ = ni / 1e8 if ni else 0
    per_s = f"{per:.1f}x" if per and not np.isnan(per) else "  -"
    v7_str = f"{v7_s:.3f}" if not np.isnan(v7_s) else "  -  "
    v6_str = f"{v6_s:.3f}" if not np.isnan(v6_s) else "  -  "
    print(f"  {i:>2}. {ticker:<10} {name:<14} {score:.4f} {v7_str}  {v3_s:.3f}  {v6_str} {price:>12,.0f}ì› {ret:>+7.1f}%  {per_s:>6} {ni_ì–µ:>7,.0f}ì–µ")

# â”€â”€ 15ì¼ vs 20ì¼ ë¹„êµ â”€â”€
print(f"\n{'='*100}")
print(f"ğŸ“Š 15ì¼ vs 20ì¼ ì „ëµ ë¹„êµ")
print(f"{'='*100}")

# 15ì¼ ì•™ìƒë¸” (ê¸°ì¡´ select_top5.pyì™€ ë™ì¼)
ens_15d = ops.normed_rank(v3_alpha * 0.5 + v6_filled * 0.5)
scores_15d = ens_15d.loc[latest_date].dropna().sort_values(ascending=False)
scores_15d = scores_15d[~scores_15d.index.isin(exclude_tickers)]

# 20ì¼ ì•™ìƒë¸” (í˜„ì¬)
scores_20d = filtered_scores

# ê²¹ì¹˜ëŠ” ì¢…ëª© ë¶„ì„
top10_15d = set(scores_15d.head(10).index)
top10_20d = set(scores_20d.head(10).index)
overlap = top10_15d & top10_20d

print(f"   15ì¼ ì „ëµ Top10: {len(top10_15d)}ì¢…ëª©")
print(f"   20ì¼ ì „ëµ Top10: {len(top10_20d)}ì¢…ëª©")
print(f"   ê²¹ì¹˜ëŠ” ì¢…ëª©: {len(overlap)}ê°œ")

if overlap:
    print(f"   â†’ ê³µí†µ: {', '.join(ticker_name.get(t, t) for t in overlap)}")

only_20d = top10_20d - top10_15d
if only_20d:
    print(f"   â†’ 20ì¼ ì „ëµì—ë§Œ: {', '.join(ticker_name.get(t, t) for t in only_20d)}")

only_15d = top10_15d - top10_20d
if only_15d:
    print(f"   â†’ 15ì¼ ì „ëµì—ë§Œ: {', '.join(ticker_name.get(t, t) for t in only_15d)}")


print(f"\n{'='*100}")
print(f"ğŸ’¡ í•´ì„")
print(f"{'='*100}")
print(f"   v7 ëª¨ë©˜í…€Ã—ì‹¤ì : 20ì¼ ê°€ê²© ìƒìŠ¹ Ã— ê±°ë˜ëŸ‰ ì•ˆì • Ã— ë ˆì¸ì§€ ê³ ìœ„ì¹˜ Ã— ì˜ì—…ì´ìµ YoY ê°œì„ ")
print(f"   v3 ê°€ê²©ëª¨ë©˜í…€:  25ì¼ ê°€ê²© ìƒìŠ¹ Ã— ê±°ë˜ëŸ‰ ì•ˆì • Ã— 28ì¼ ë ˆì¸ì§€ ê³ ìœ„ì¹˜")
print(f"   v6 ì¬ë¬´ì¶”ì„¸:    ì˜ì—…ì´ìµ 3Qì¶”ì„¸ + YoY + QoQ ê°œì„ ë„ ë­í‚¹ í•©ì‚°")
print(f"   ê°€ì†ë„:         ìµœê·¼ 10ì¼ ìˆ˜ìµë¥  - ì´ì „ 10ì¼ ìˆ˜ìµë¥  (â†‘=ê°€ì†, â†“=ê°ì†)")
print(f"   â†’ 20ì˜ì—…ì¼(ì•½ 1ë‹¬) ë³´ìœ  ì „ëµì— ìµœì í™”")
print(f"   â†’ v7ì´ 'ì‹¤ì  ê°œì„  + ê°€ê²© ë°˜ì˜ ì´ˆê¸°' ì¢…ëª©ì„ í¬ì°©")
print(f"   â†’ v6 ë¹„ì¤‘ 50%ë¡œ ì‹¤ì  ì¶”ì„¸ì— ê°€ì¥ í° ê°€ì¤‘ì¹˜")
