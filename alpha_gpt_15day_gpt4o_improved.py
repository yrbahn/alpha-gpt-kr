#!/usr/bin/env python3
"""
Alpha-GPT: 15-day Forward with GPT-4o (v2 â€” Improved Prompt)
ê°œì„ ëœ QuantDeveloper í”„ë¡¬í”„íŠ¸ + ops.xxx() ë¬¸ë²• + ë³‘ë ¬ GP
"""

import sys
import os
import re
import json
from pathlib import Path
import pandas as pd
import numpy as np
from dotenv import load_dotenv
import psycopg2
import openai
import random
import gc
from multiprocessing import Pool

project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from alpha_gpt_kr.mining.operators import AlphaOperators as ops
from alpha_gpt_kr.agents.quant_developer import QuantDeveloper

load_dotenv()

def get_db_connection():
    return psycopg2.connect(
        host=os.getenv('DB_HOST', '192.168.0.248'),
        port=int(os.getenv('DB_PORT', 5432)),
        database=os.getenv('DB_NAME', 'marketsense'),
        user=os.getenv('DB_USER', 'yrbahn'),
        password=os.getenv('DB_PASSWORD', '1234')
    )

def load_market_data():
    """500ê°œ ì¢…ëª© ë°ì´í„° ë¡œë“œ (ì‹œê°€ì´ì•¡ ìƒìœ„)"""
    print("ğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘... (ì‹œì´ ìƒìœ„ 500ì¢…ëª©, 2ë…„)")
    
    conn = get_db_connection()
    
    # ì‹œê°€ì´ì•¡ ìƒìœ„ 500ê°œ
    query_stocks = """
        SELECT 
            s.id,
            s.ticker,
            s.name,
            s.market_cap
        FROM stocks s
        WHERE s.is_active = true
        AND s.market_cap IS NOT NULL
        AND EXISTS (
            SELECT 1 FROM price_data p 
            WHERE p.stock_id = s.id 
            AND p.date >= CURRENT_DATE - INTERVAL '730 days'
            LIMIT 1
        )
        ORDER BY s.market_cap DESC
        LIMIT 500
    """
    
    stocks_df = pd.read_sql(query_stocks, conn)
    stock_ids = stocks_df['id'].tolist()
    stock_id_list = ', '.join(map(str, stock_ids))
    
    query_prices = f"""
        SELECT 
            s.ticker,
            p.date,
            p.close,
            p.volume
        FROM price_data p
        JOIN stocks s ON p.stock_id = s.id
        WHERE p.stock_id IN ({stock_id_list})
        AND p.date >= CURRENT_DATE - INTERVAL '730 days'
        ORDER BY s.ticker, p.date
    """
    
    price_df = pd.read_sql(query_prices, conn)
    conn.close()
    
    close = price_df.pivot(index='date', columns='ticker', values='close')
    volume = price_df.pivot(index='date', columns='ticker', values='volume')
    
    print(f"âœ… {len(close.columns)}ê°œ ì¢…ëª©, {len(close)}ì¼ ë°ì´í„°")
    
    return {
        'close': close,
        'volume': volume,
        'returns': close.pct_change()
    }

def generate_seed_alphas_gpt4o(num_seeds=20):
    """GPT-4o + ê°œì„ ëœ QuantDeveloper í”„ë¡¬í”„íŠ¸ë¡œ ì‹œë“œ ì•ŒíŒŒ ìƒì„±"""
    print(f"\nğŸ¤– GPT-4oë¡œ ì´ˆê¸° ì•ŒíŒŒ {num_seeds}ê°œ ìƒì„± ì¤‘ (ê°œì„ ëœ í”„ë¡¬í”„íŠ¸)...")

    client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

    # QuantDeveloperì˜ ê°œì„ ëœ í”„ë¡¬í”„íŠ¸ ì¬ì‚¬ìš©
    system_prompt = QuantDeveloper.SYSTEM_PROMPT

    # 15ì¼ ë³´ìœ ì— íŠ¹í™”ëœ user prompt
    prompt = f"""### Task
Generate {num_seeds} diverse, high-performance alpha expressions optimized for **15-day forward returns** in the Korean stock market.

### Trading Idea
15ì¼ ë³´ìœ  ì „ëµì— ìµœì í™”ëœ ì¤‘ê¸° ì•ŒíŒŒ íŒ©í„°. ë‹¨ê¸° ë…¸ì´ì¦ˆë¥¼ í•„í„°ë§í•˜ê³ ,
15ì¼ í›„ ìˆ˜ìµë¥ ê³¼ ë†’ì€ ìƒê´€ê´€ê³„(IC)ë¥¼ ê°€ì§€ëŠ” ì‹œê·¸ë„ì„ ì°¾ì•„ì•¼ í•¨.
ëª¨ë©˜í…€, ê±°ë˜ëŸ‰, ë³€ë™ì„±, ì¶”ì„¸ ê°•ë„ë¥¼ ì¡°í•©í•˜ì—¬ ë‹¤ì–‘í•œ íŒ©í„°ë¥¼ ìƒì„±.

### Available Data Fields
close, volume, returns

### Requirements

**Diversity** â€” Each alpha MUST belong to a DIFFERENT category:
  1. `momentum_volume` â€” Momentum confirmed by volume surge
  2. `volatility_adjusted` â€” Signal adjusted/filtered by volatility
  3. `short_term_reversal` â€” Mean-reversion exploiting KRX reversal effect
  4. `multi_timeframe` â€” Combining short + medium + long timeframes
  5. `price_volume_diverge` â€” Price-volume divergence / smart money
  6. `trend_strength` â€” Trend strength via regression slope or IR
  7. `tail_risk` â€” Skewness/kurtosis-based risk signal
  8. `price_position` â€” Price position relative to recent high/low
  9. `volume_anomaly` â€” Abnormal volume detection
  10. `composite` â€” 3+ factor composite signal
  11. `momentum_volume` â€” Variation with different timeframes
  12. `volatility_adjusted` â€” Variation with different approach
  13. `short_term_reversal` â€” Variation with volume filter
  14. `multi_timeframe` â€” Variation with volatility
  15. `price_volume_diverge` â€” Variation with trend
  16. `trend_strength` â€” Variation with volume
  17. `composite` â€” Different 3+ factor combination
  18. `price_position` â€” Variation with momentum
  19. `volume_anomaly` â€” Variation with reversal
  20. `composite` â€” Most complex combination

**15-Day Holding Optimization**:
- Prefer medium-term lookback windows: 10, 15, 20, 30 days (not too short like 3d, not too long like 60d)
- Combine at least 2 timeframes per alpha
- Volume confirmation is critical for 15-day predictions

**Quality Checklist** â€” Every alpha must satisfy ALL:
- [ ] Multi-factor: combines 2+ distinct signal types
- [ ] Market-neutral: wrapped with `ops.normed_rank()` or `ops.zscore_scale()`
- [ ] Multi-timeframe: uses 2+ lookback windows
- [ ] No look-ahead bias
- [ ] Complexity 2~4 nesting levels
- [ ] Safe division: use `ops.div()` instead of raw `/`

### Output Format
Return a JSON array:
```json
[
  {{
    "alpha_name": "Alpha_Name",
    "category": "category_name",
    "rationale": "Economic logic explanation",
    "expression": "ops.normed_rank(...)",
    "complexity": 4,
    "operators_used": ["op1", "op2"],
    "timeframes_used": [10, 20]
  }}
]
```

**CRITICAL**:
- You MUST return a JSON object with key "alphas" containing an array of {num_seeds} alpha objects.
- Format: {{"alphas": [{{...}}, {{...}}, ...]}}
- Each object MUST have "expression" field with valid ops.xxx() Python code.
- Generate ALL {num_seeds} alphas. Do NOT return just 1."""

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt}
        ],
        temperature=0.7,
        max_tokens=16000,
        response_format={"type": "json_object"}
    )

    content = response.choices[0].message.content
    print(f"   GPT-4o ì‘ë‹µ ê¸¸ì´: {len(content)}ì")
    print(f"   ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {content[:200]}...")

    # JSON íŒŒì‹±
    alphas = []
    try:
        data = json.loads(content)
        print(f"   íŒŒì‹±ëœ íƒ€ì…: {type(data).__name__}")

        # dict â†’ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
        if isinstance(data, dict):
            print(f"   í‚¤ ëª©ë¡: {list(data.keys())}")

            # 1ìˆœìœ„: dict ìì²´ê°€ ë‹¨ì¼ ì•ŒíŒŒì¸ ê²½ìš° (expression í‚¤ ì¡´ì¬)
            if 'expression' in data or 'expr' in data:
                data = [data]
                print(f"   ë‹¨ì¼ ì•ŒíŒŒ dict â†’ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜")

            else:
                # 2ìˆœìœ„: {"alphas": [{...}, ...]} í˜•íƒœ â€” dict ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì§„ í‚¤ ì°¾ê¸°
                found_list = False
                for key in data:
                    if isinstance(data[key], list) and data[key] and isinstance(data[key][0], dict):
                        data = data[key]
                        print(f"   '{key}' í‚¤ì—ì„œ {len(data)}ê°œ í•­ëª© ì¶”ì¶œ")
                        found_list = True
                        break

                if not found_list:
                    # 3ìˆœìœ„: ì¤‘ì²© dict: {"alpha_1": {...}, "alpha_2": {...}}
                    items = []
                    for key, val in data.items():
                        if isinstance(val, dict) and ('expression' in val or 'expr' in val):
                            items.append(val)
                    if items:
                        data = items
                        print(f"   ì¤‘ì²© dictì—ì„œ {len(items)}ê°œ í•­ëª© ì¶”ì¶œ")
                    else:
                        print(f"   âš ï¸  ì•Œ ìˆ˜ ì—†ëŠ” dict êµ¬ì¡°: {list(data.keys())[:5]}")
                        data = []

        for item in data:
            if isinstance(item, str):
                if 'ops.' in item:
                    alphas.append(item)
                continue
            if not isinstance(item, dict):
                continue
            expr = item.get('expression', item.get('expr', ''))
            if expr and 'ops.' in expr:
                alphas.append(expr)
            elif expr:
                print(f"   âš ï¸  ops. ì—†ëŠ” í‘œí˜„ì‹ ìŠ¤í‚µ: {expr[:80]}")

    except (json.JSONDecodeError, Exception) as e:
        print(f"âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì•ˆì˜ JSON ì¶”ì¶œ ì‹œë„
        json_match = re.search(r'```(?:json)?\s*(\[.*?\])\s*```', content, re.DOTALL)
        if json_match:
            try:
                data = json.loads(json_match.group(1))
                for item in data:
                    if isinstance(item, dict):
                        expr = item.get('expression', item.get('expr', ''))
                        if expr and 'ops.' in expr:
                            alphas.append(expr)
                print(f"   ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ì—ì„œ {len(alphas)}ê°œ ë³µêµ¬")
            except Exception:
                pass

    # í´ë°±: ê°œì„ ëœ ë³µí•© íŒ©í„°
    if len(alphas) < 10:
        print(f"âš ï¸  {len(alphas)}ê°œë§Œ íŒŒì‹±ë¨, í´ë°± ì¶”ê°€")
        fallback = [
            "ops.normed_rank(ops.cwise_mul(ops.ts_delta_ratio(close, 15), ops.div(ops.ts_mean(volume, 5), ops.ts_mean(volume, 20))))",
            "ops.normed_rank(ops.div(ops.neg(ops.ts_zscore_scale(close, 10)), ops.ts_std(returns, 20)))",
            "ops.normed_rank(ops.neg(ops.ts_corr(ops.ts_delta(close, 5), ops.ts_delta(volume, 5), 20)))",
            "ops.normed_rank(ops.minus(ops.ts_ir(returns, 5), ops.ts_ir(returns, 20)))",
            "ops.normed_rank(ops.cwise_mul(ops.ts_maxmin_scale(close, 20), ops.normed_rank(ops.ts_mean(volume, 5))))",
            "ops.normed_rank(ops.cwise_mul(ops.relu(ops.ts_linear_reg(close, 20)), ops.relu(ops.ts_skew(returns, 20))))",
            "ops.normed_rank(ops.cwise_mul(ops.cwise_mul(ops.greater(ops.ts_delta_ratio(volume, 5), 0.5), ops.less(ops.ts_delta_ratio(close, 5), 0)), ops.neg(ops.normed_rank(ops.ts_std(returns, 20)))))",
            "ops.normed_rank(ops.cwise_mul(ops.ts_delta_ratio(close, 10), ops.div(ops.ts_mean(volume, 10), ops.ts_mean(volume, 30))))",
            "ops.normed_rank(ops.minus(ops.ts_linear_reg(close, 10), ops.ts_linear_reg(close, 30)))",
            "ops.normed_rank(ops.div(ops.ts_max_diff(close, 20), ops.ts_std(close, 20)))",
            "ops.normed_rank(ops.cwise_mul(ops.ts_delta_ratio(close, 20), ops.neg(ops.ts_skew(returns, 15))))",
            "ops.normed_rank(ops.div(ops.ts_min_diff(close, 15), ops.ts_std(returns, 15)))",
        ]
        alphas = alphas + [f for f in fallback if f not in alphas]

    print(f"âœ… {len(alphas)}ê°œ ì´ˆê¸° ì•ŒíŒŒ ìƒì„±")
    for i, a in enumerate(alphas[:5], 1):
        print(f"   {i}. {a[:80]}...")

    return alphas[:num_seeds]

# ì „ì—­ ë°ì´í„°
_global_data = None

def set_global_data(data):
    global _global_data
    _global_data = data

def _compute_raw_ic(alpha_expr, data):
    """ì•ŒíŒŒì˜ raw IC ê³„ì‚° (train ë˜ëŠ” test ë°ì´í„°)"""
    close = data['close']
    volume = data['volume']
    returns = data['returns']

    forward_return_15d = close.shift(-15) / close - 1
    alpha_values = eval(alpha_expr)

    if not isinstance(alpha_values, pd.DataFrame):
        return -999.0

    ic_list = []
    for date in alpha_values.index[:-15]:
        alpha_cs = alpha_values.loc[date]
        returns_cs = forward_return_15d.loc[date]
        valid = alpha_cs.notna() & returns_cs.notna()

        if valid.sum() > 30:
            ic = alpha_cs[valid].corr(returns_cs[valid])
            if not np.isnan(ic):
                ic_list.append(ic)

    if len(ic_list) < 10:
        return -999.0

    return float(np.mean(ic_list))

def _multi_factor_bonus(alpha_expr):
    """ë‹¤ì¤‘ íŒ©í„° êµ¬ì¡° ë³´ë„ˆìŠ¤"""
    bonus = 0.0
    # ê±°ë˜ëŸ‰ ì‚¬ìš© ë³´ë„ˆìŠ¤
    if 'volume' in alpha_expr:
        bonus += 0.003
    # ë‹¤ì¤‘ íƒ€ì„í”„ë ˆì„ ë³´ë„ˆìŠ¤ (ìœˆë„ìš° ì°¨ì´ â‰¥ 2ë°°)
    windows = [int(w) for w in re.findall(r',\s*(\d+)\)', alpha_expr)]
    if len(windows) >= 2:
        if max(windows) >= min(windows) * 2:
            bonus += 0.002
    # ë³µì¡ë„ í˜ë„í‹°
    depth = alpha_expr.count('(')
    if depth < 3:
        bonus -= 0.002
    if depth > 8:
        bonus -= 0.003
    return bonus

def evaluate_alpha_worker(alpha_expr):
    """ë³‘ë ¬ ì²˜ë¦¬ìš© ì•ŒíŒŒ í‰ê°€ â€” train IC + ë‹¤ì¤‘íŒ©í„° ë³´ë„ˆìŠ¤"""
    global _global_data
    data = _global_data

    try:
        raw_ic = _compute_raw_ic(alpha_expr, data)
        if raw_ic <= -999.0:
            return (alpha_expr, -999.0)
        bonus = _multi_factor_bonus(alpha_expr)
        return (alpha_expr, raw_ic + bonus)
    except Exception:
        return (alpha_expr, -999.0)

def evaluate_alpha_oos(alpha_expr, test_data):
    """Out-of-sample IC ê³„ì‚° (ë³´ë„ˆìŠ¤ ì—†ì´ ìˆœìˆ˜ IC)"""
    try:
        return _compute_raw_ic(alpha_expr, test_data)
    except Exception:
        return -999.0

# ì—°ì‚°ì êµí™˜ ê·¸ë£¹ (ê°™ì€ ì‹œê·¸ë‹ˆì²˜ë¼ë¦¬ë§Œ êµì²´)
OPERATOR_SWAP_GROUPS = [
    ['ts_mean', 'ts_std', 'ts_median', 'ts_ema', 'ts_linear_reg', 'ts_decayed_linear'],
    ['ts_zscore_scale', 'ts_maxmin_scale', 'ts_rank'],
    ['ts_delta', 'ts_delta_ratio'],
    ['ts_skew', 'ts_kurt', 'ts_ir'],
    ['ts_min', 'ts_max'],
    ['ts_argmin', 'ts_argmax'],
    ['ts_max_diff', 'ts_min_diff'],
    ['normed_rank', 'zscore_scale'],
    ['cwise_mul', 'add', 'minus'],
]

OPERAND_POOL = ['close', 'volume', 'returns']

def mutate_alpha(alpha_expr):
    """ì•ŒíŒŒ ë³€ì´ â€” 3ê°€ì§€ íƒ€ì…: ìœˆë„ìš°(50%), ì—°ì‚°ì(30%), í”¼ì—°ì‚°ì(20%)"""
    try:
        mutation_type = random.choices(
            ['window', 'operator', 'operand'],
            weights=[0.5, 0.3, 0.2]
        )[0]

        if mutation_type == 'window':
            return _mutate_window(alpha_expr)
        elif mutation_type == 'operator':
            return _mutate_operator(alpha_expr)
        else:
            return _mutate_operand(alpha_expr)
    except Exception:
        return None

def _mutate_window(alpha_expr):
    """ìœˆë„ìš° íŒŒë¼ë¯¸í„° ë³€ê²½ (ë²”ìœ„ 5~50)"""
    matches = list(re.finditer(r'(ts_\w+|shift)\([^,]+,\s*(\d+)\)', alpha_expr))
    if not matches:
        return None
    match = random.choice(matches)
    old_window = int(match.group(2))
    new_window = max(5, min(50, old_window + random.choice([-7, -5, -3, -2, 2, 3, 5, 7, 10])))
    if new_window == old_window:
        new_window = max(5, old_window + random.choice([-10, 10]))
    start, end = match.span(2)
    return alpha_expr[:start] + str(new_window) + alpha_expr[end:]

def _mutate_operator(alpha_expr):
    """ì—°ì‚°ì êµì²´ â€” ê°™ì€ ì‹œê·¸ë‹ˆì²˜ ê·¸ë£¹ ë‚´ì—ì„œë§Œ"""
    # í˜„ì¬ í‘œí˜„ì‹ì—ì„œ ì—°ì‚°ì ì¶”ì¶œ
    op_matches = list(re.finditer(r'ops\.(\w+)\(', alpha_expr))
    if not op_matches:
        return None

    # êµí™˜ ê°€ëŠ¥í•œ ì—°ì‚°ìë§Œ í•„í„°
    swappable = []
    for m in op_matches:
        op_name = m.group(1)
        for group in OPERATOR_SWAP_GROUPS:
            if op_name in group:
                swappable.append((m, op_name, group))
                break

    if not swappable:
        return _mutate_window(alpha_expr)  # êµí™˜ ë¶ˆê°€ë©´ ìœˆë„ìš° ë³€ì´

    match, old_op, group = random.choice(swappable)
    candidates = [op for op in group if op != old_op]
    if not candidates:
        return _mutate_window(alpha_expr)

    new_op = random.choice(candidates)
    start, end = match.span(1)
    return alpha_expr[:start] + new_op + alpha_expr[end:]

def _mutate_operand(alpha_expr):
    """í”¼ì—°ì‚°ì êµì²´ â€” close/volume/returns ê°„ êµí™˜"""
    present = [op for op in OPERAND_POOL if op in alpha_expr]
    if not present:
        return _mutate_window(alpha_expr)

    old_operand = random.choice(present)
    candidates = [op for op in OPERAND_POOL if op != old_operand]
    new_operand = random.choice(candidates)

    # ì²« ë²ˆì§¸ ë“±ì¥ë§Œ êµì²´ (ì „ì²´ êµì²´ ë°©ì§€)
    return alpha_expr.replace(old_operand, new_operand, 1)


def crossover_alphas(alpha1, alpha2):
    """ì•ŒíŒŒ êµì°¨ â€” ë‘ ì•ŒíŒŒì˜ ìœˆë„ìš° íŒŒë¼ë¯¸í„°ë¥¼ êµí™˜"""
    try:
        matches1 = list(re.finditer(r'(ts_\w+|shift)\(([^,]+),\s*(\d+)\)', alpha1))
        matches2 = list(re.finditer(r'(ts_\w+|shift)\(([^,]+),\s*(\d+)\)', alpha2))

        if not matches1 or not matches2:
            return None

        # ê°™ì€ ì—°ì‚°ìê°€ ìˆìœ¼ë©´ ìš°ì„  êµì°¨
        ops1 = {m.group(1): m for m in matches1}
        ops2 = {m.group(1): m for m in matches2}
        common_ops = set(ops1.keys()) & set(ops2.keys())

        if common_ops:
            op = random.choice(list(common_ops))
            m1, m2 = ops1[op], ops2[op]
        else:
            m1 = random.choice(matches1)
            m2 = random.choice(matches2)

        # alpha1ì˜ ìœˆë„ìš°ë¥¼ alpha2ì˜ ê°’ìœ¼ë¡œ êµì²´
        win2 = m2.group(3)
        start, end = m1.span(3)
        return alpha1[:start] + win2 + alpha1[end:]
    except Exception:
        return None

def _get_alpha_structure(alpha_expr):
    """ì•ŒíŒŒì˜ êµ¬ì¡° ì‹œê·¸ë‹ˆì²˜ (ìœˆë„ìš° ì œê±°) â€” ë‹¤ì–‘ì„± ë¹„êµìš©"""
    return re.sub(r',\s*\d+\)', ', N)', alpha_expr)

def _select_diverse_top_n(results, n=5):
    """IC ìƒìœ„ì—ì„œ êµ¬ì¡°ê°€ ë‹¤ë¥¸ Top-N ì„ íƒ"""
    sorted_results = sorted(results, key=lambda x: x[1], reverse=True)
    selected = []
    seen_structures = set()

    for alpha, ic in sorted_results:
        if ic <= -999.0:
            continue
        structure = _get_alpha_structure(alpha)
        if structure not in seen_structures:
            selected.append((alpha, ic))
            seen_structures.add(structure)
            if len(selected) >= n:
                break

    return selected

def genetic_programming(seed_alphas, data, generations=40, population_size=150):
    """ê°œì„ ëœ ë³‘ë ¬ GP â€” êµ¬ì¡°ì  ë³€ì´ + ë‹¤ì–‘ì„± ë³´ì¡´ + ì¡°ê¸°ì¢…ë£Œ"""

    print(f"\nğŸ§¬ ë³‘ë ¬ GP ì‹œì‘ (ê°œì„ ë¨)")
    print(f"   Seed: {len(seed_alphas)}ê°œ, ì„¸ëŒ€: {generations}, ê°œì²´ìˆ˜: {population_size}, ì›Œì»¤: 4")

    population = seed_alphas[:population_size]
    while len(population) < population_size:
        parent = random.choice(seed_alphas)
        mutated = mutate_alpha(parent)
        if mutated:
            population.append(mutated)

    set_global_data(data)
    best_ever = (None, -999.0)
    stagnation_count = 0
    all_results_history = []  # ëª¨ë“  ì„¸ëŒ€ì˜ ê²°ê³¼ ë³´ê´€

    elite_count = max(5, population_size // 10)  # 10% ì—˜ë¦¬íŠ¸
    parent_pool_size = 30

    for gen in range(1, generations + 1):
        print(f"\n  ì„¸ëŒ€ {gen}/{generations}")

        with Pool(4, initializer=set_global_data, initargs=(data,)) as pool:
            results = pool.map(evaluate_alpha_worker, population)

        fitness_scores = sorted(results, key=lambda x: x[1], reverse=True)
        all_results_history.extend([(a, ic) for a, ic in fitness_scores if ic > -999.0])

        best_ic = fitness_scores[0][1]
        print(f"    ìµœê³  IC: {best_ic:.4f}")

        if best_ic > best_ever[1]:
            best_ever = fitness_scores[0]
            stagnation_count = 0
            print(f"    ğŸ† ì‹ ê¸°ë¡!")
        else:
            stagnation_count += 1

        # ì¡°ê¸°ì¢…ë£Œ: 5ì„¸ëŒ€ ì—°ì† ë¬´ê°œì„ 
        if stagnation_count >= 5:
            print(f"    â¹ï¸  5ì„¸ëŒ€ ë¬´ê°œì„  â†’ ì¡°ê¸°ì¢…ë£Œ")
            break

        # ë‹¤ìŒ ì„¸ëŒ€ êµ¬ì„±
        next_population = []

        # ì—˜ë¦¬íŠ¸ ë³´ì¡´ (10%)
        for alpha, _ in fitness_scores[:elite_count]:
            next_population.append(alpha)

        # ë‚˜ë¨¸ì§€: êµì°¨(60%) + ë³€ì´(40%)
        parent_pool = [a for a, ic in fitness_scores[:parent_pool_size]]

        while len(next_population) < population_size:
            if random.random() < 0.6:
                # êµì°¨
                parent1 = random.choice(parent_pool)
                parent2 = random.choice(parent_pool)
                child = crossover_alphas(parent1, parent2)
                if child:
                    next_population.append(child)
                else:
                    next_population.append(parent1)
            else:
                # ë³€ì´ (êµ¬ì¡°ì  ë³€ì´ í¬í•¨)
                parent = random.choice(parent_pool)
                mutated = mutate_alpha(parent)
                if mutated:
                    next_population.append(mutated)
                else:
                    next_population.append(parent)

        population = next_population[:population_size]

        del results, fitness_scores, next_population
        gc.collect()

    # Top-5 ë‹¤ì–‘í•œ ì•ŒíŒŒ ì„ íƒ
    top_diverse = _select_diverse_top_n(all_results_history, n=5)

    return best_ever, top_diverse

def main():
    print("=" * 80)
    print("Alpha-GPT: 15-day Forward with GPT-4o (v3 â€” Enhanced GP)")
    print("=" * 80)
    print()

    # 1. ì „ì²´ ë°ì´í„° ë¡œë“œ
    full_data = load_market_data()

    # 2. Train/Test ë¶„í•  (70/30)
    close = full_data['close']
    split_idx = int(len(close) * 0.7)
    split_date = close.index[split_idx]
    print(f"\nğŸ“ Train/Test ë¶„í• : {split_idx}ì¼ train / {len(close) - split_idx}ì¼ test")
    print(f"   Train: ~{close.index[0]} ~ {close.index[split_idx-1]}")
    print(f"   Test:  ~{split_date} ~ {close.index[-1]}")

    train_data = {
        'close': full_data['close'].iloc[:split_idx],
        'volume': full_data['volume'].iloc[:split_idx],
        'returns': full_data['returns'].iloc[:split_idx],
    }
    test_data = {
        'close': full_data['close'].iloc[split_idx:],
        'volume': full_data['volume'].iloc[split_idx:],
        'returns': full_data['returns'].iloc[split_idx:],
    }

    # 3. GPT-4o ì‹œë“œ ìƒì„±
    seed_alphas = generate_seed_alphas_gpt4o()

    # 4. GP ì§„í™” (train ë°ì´í„°ë¡œ)
    (best_alpha, best_ic), top_diverse = genetic_programming(
        seed_alphas,
        train_data,
        generations=40,
        population_size=150
    )

    # 5. Top-5 OOS ê²€ì¦
    print("\n" + "=" * 80)
    print("ğŸ† TOP 5 ALPHAS (Train IC + Test IC)")
    print("=" * 80)

    validated_alphas = []
    for i, (alpha, train_ic_with_bonus) in enumerate(top_diverse, 1):
        # ìˆœìˆ˜ train IC (ë³´ë„ˆìŠ¤ ì œê±°)
        train_ic = _compute_raw_ic(alpha, train_data)
        # OOS test IC
        test_ic = evaluate_alpha_oos(alpha, test_data)
        # íŒ©í„° ë¶„ë¥˜
        factors = []
        if any(kw in alpha for kw in ['close', 'open_price', 'high', 'low']):
            factors.append('price')
        if 'volume' in alpha:
            factors.append('volume')
        if 'returns' in alpha:
            factors.append('returns')
        factor_str = '+'.join(factors) if factors else 'unknown'

        status = "âœ…" if test_ic > 0.015 else "âš ï¸"
        print(f"\n  #{i} {status}")
        print(f"     Train IC: {train_ic:.4f}  |  Test IC: {test_ic:.4f}  [{factor_str}]")
        print(f"     {alpha[:100]}{'...' if len(alpha) > 100 else ''}")

        validated_alphas.append({
            'expr': alpha,
            'train_ic': train_ic,
            'test_ic': test_ic,
            'factors': factor_str,
        })

    # 6. ìµœì¢… Best ì„ ì • (test ICê°€ ì–‘ìˆ˜ì¸ ê²ƒ ì¤‘ train IC ìµœê³ )
    valid_alphas = [a for a in validated_alphas if a['test_ic'] > 0]
    if valid_alphas:
        final_best = max(valid_alphas, key=lambda x: x['train_ic'])
    else:
        final_best = validated_alphas[0] if validated_alphas else {'expr': best_alpha, 'train_ic': best_ic, 'test_ic': -999, 'factors': '?'}

    print("\n" + "=" * 80)
    print("ğŸ¥‡ FINAL BEST (OOS-validated)")
    print("=" * 80)
    print(f"Train IC: {final_best['train_ic']:.4f}")
    print(f"Test IC:  {final_best['test_ic']:.4f}")
    print(f"Factors:  {final_best['factors']}")
    print(f"Expression: {final_best['expr']}")

    # 7. DB ì €ì¥ (Top-5 ì „ë¶€)
    print("\nğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì¤‘...")
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        for a in validated_alphas:
            cursor.execute("""
                INSERT INTO alpha_formulas (formula, ic_score, description, created_at)
                VALUES (%s, %s, %s, NOW())
                ON CONFLICT (formula) DO UPDATE
                SET ic_score = EXCLUDED.ic_score, updated_at = NOW()
            """, (
                a['expr'],
                float(a['train_ic']),
                f"15d fwd, train IC={a['train_ic']:.4f}, test IC={a['test_ic']:.4f}, factors={a['factors']}, v3-enhanced"
            ))

        conn.commit()
        cursor.close()
        conn.close()
        print(f"âœ… {len(validated_alphas)}ê°œ ì•ŒíŒŒ ì €ì¥ ì™„ë£Œ!")
    except Exception as e:
        print(f"âš ï¸  DB ì €ì¥ ì‹¤íŒ¨: {e}")

    print("\nğŸ‰ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
